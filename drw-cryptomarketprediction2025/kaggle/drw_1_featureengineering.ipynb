{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b496e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:46:34.627835Z",
     "iopub.status.busy": "2025-06-14T09:46:34.627243Z",
     "iopub.status.idle": "2025-06-14T09:46:34.635107Z",
     "shell.execute_reply": "2025-06-14T09:46:34.634500Z"
    },
    "papermill": {
     "duration": 0.013712,
     "end_time": "2025-06-14T09:46:34.636164",
     "exception": false,
     "start_time": "2025-06-14T09:46:34.622452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\n",
      "/kaggle/input/drw-crypto-market-prediction/train.parquet\n",
      "/kaggle/input/drw-crypto-market-prediction/test.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081d2b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:46:34.643364Z",
     "iopub.status.busy": "2025-06-14T09:46:34.643182Z",
     "iopub.status.idle": "2025-06-14T09:46:34.646226Z",
     "shell.execute_reply": "2025-06-14T09:46:34.645712Z"
    },
    "papermill": {
     "duration": 0.007747,
     "end_time": "2025-06-14T09:46:34.647241",
     "exception": false,
     "start_time": "2025-06-14T09:46:34.639494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ.get(\"USER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6d205",
   "metadata": {
    "papermill": {
     "duration": 0.002685,
     "end_time": "2025-06-14T09:46:34.652857",
     "exception": false,
     "start_time": "2025-06-14T09:46:34.650172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DRW - Crypto Market Prediction\n",
    "\n",
    "This notebook documents all the steps done in this project.\n",
    "\n",
    "Timeline:\n",
    "- 10/06/25: 0.05031\n",
    "    - Reorganize notebooks.\n",
    "    - Test training with GPU - Way faster than CPU.\n",
    "    - Implement feature elimination using GPU.\n",
    "    - Tested with Linear Models - will be extremely slow in iteration.\n",
    "    - Develop feature engineering pipeline\n",
    "- 14/06/25\n",
    "    - redevelop feature engineering pipeline - pipe results into downloadable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff23a03f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-14T09:46:34.659297Z",
     "iopub.status.busy": "2025-06-14T09:46:34.659109Z",
     "iopub.status.idle": "2025-06-14T09:47:04.025538Z",
     "shell.execute_reply": "2025-06-14T09:47:04.024697Z"
    },
    "papermill": {
     "duration": 29.371099,
     "end_time": "2025-06-14T09:47:04.026833",
     "exception": false,
     "start_time": "2025-06-14T09:46:34.655734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (525_887, 897)\n",
      "┌─────────┬─────────┬─────────┬──────────┬───┬──────────┬──────────┬──────────┬──────────────┐\n",
      "│ bid_qty ┆ ask_qty ┆ buy_qty ┆ sell_qty ┆ … ┆ X889     ┆ X890     ┆ label    ┆ timestamp    │\n",
      "│ ---     ┆ ---     ┆ ---     ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---          │\n",
      "│ f64     ┆ f64     ┆ f64     ┆ f64      ┆   ┆ f64      ┆ f64      ┆ f64      ┆ datetime[ns] │\n",
      "╞═════════╪═════════╪═════════╪══════════╪═══╪══════════╪══════════╪══════════╪══════════════╡\n",
      "│ 15.283  ┆ 8.425   ┆ 176.405 ┆ 44.984   ┆ … ┆ 0.159183 ┆ 0.530636 ┆ 0.562539 ┆ 2023-03-01   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:00:00     │\n",
      "│ 38.59   ┆ 2.336   ┆ 525.846 ┆ 321.95   ┆ … ┆ 0.158963 ┆ 0.530269 ┆ 0.533686 ┆ 2023-03-01   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:01:00     │\n",
      "│ 0.442   ┆ 60.25   ┆ 159.227 ┆ 136.369  ┆ … ┆ 0.158744 ┆ 0.529901 ┆ 0.546505 ┆ 2023-03-01   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:02:00     │\n",
      "│ 4.865   ┆ 21.016  ┆ 335.742 ┆ 124.963  ┆ … ┆ 0.158524 ┆ 0.529534 ┆ 0.357703 ┆ 2023-03-01   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:03:00     │\n",
      "│ 27.158  ┆ 3.451   ┆ 98.411  ┆ 44.407   ┆ … ┆ 0.158304 ┆ 0.529167 ┆ 0.362452 ┆ 2023-03-01   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:04:00     │\n",
      "│ …       ┆ …       ┆ …       ┆ …        ┆ … ┆ …        ┆ …        ┆ …        ┆ …            │\n",
      "│ 4.163   ┆ 6.805   ┆ 39.037  ┆ 55.351   ┆ … ┆ 0.136494 ┆ 0.243172 ┆ 0.396289 ┆ 2024-02-29   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:55:00     │\n",
      "│ 2.29    ┆ 4.058   ┆ 110.201 ┆ 67.171   ┆ … ┆ 0.136305 ┆ 0.243004 ┆ 0.328993 ┆ 2024-02-29   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:56:00     │\n",
      "│ 5.237   ┆ 3.64    ┆ 70.499  ┆ 30.753   ┆ … ┆ 0.136117 ┆ 0.242836 ┆ 0.189909 ┆ 2024-02-29   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:57:00     │\n",
      "│ 5.731   ┆ 4.901   ┆ 22.365  ┆ 52.195   ┆ … ┆ 0.135928 ┆ 0.242668 ┆ 0.410831 ┆ 2024-02-29   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:58:00     │\n",
      "│ 3.925   ┆ 3.865   ┆ 86.585  ┆ 217.137  ┆ … ┆ 0.135741 ┆ 0.242501 ┆ 0.731542 ┆ 2024-02-29   │\n",
      "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:59:00     │\n",
      "└─────────┴─────────┴─────────┴──────────┴───┴──────────┴──────────┴──────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "train_splits = {\n",
    "    \"full\" : pl.datetime(2023, 3, 1, 0, 0, 0),\n",
    "    \"last_9m\" : pl.datetime(2023, 6, 1, 0, 0, 0),\n",
    "    \"last_6m\" : pl.datetime(2023, 9, 1, 0, 0, 0),\n",
    "    \"last_3m\" : pl.datetime(2023, 12, 1, 0, 0, 0),\n",
    "    \"last_1m\": pl.datetime(2024, 2, 1, 0, 0, 0),\n",
    "    \"last_2w\": pl.datetime(2024, 2, 15, 0, 0, 0),\n",
    "}\n",
    "\n",
    "PATHS = {\n",
    "    \"TRAIN_PATH\" :\"/kaggle/input/drw-crypto-market-prediction/train.parquet\",\n",
    "    \"TEST_PATH\" : \"/kaggle/input/drw-crypto-market-prediction/test.parquet\",\n",
    "    \"SUBMISSION_PATH\" : \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\",\n",
    "}\n",
    "\n",
    "# features = []\n",
    "\n",
    "def load_data(TRAIN_PATH: str, TEST_PATH: str):\n",
    "    if os.environ.get(\"USER\"):\n",
    "        TRAIN_PATH = \".\" + TRAIN_PATH\n",
    "        TEST_PATH = \".\" + TEST_PATH\n",
    "    train_data = pl.read_parquet(TRAIN_PATH).sort(\"timestamp\", descending = False)\n",
    "    test_data = pl.read_parquet(TEST_PATH)\n",
    "    # print(f\"Train data shape: {train_data.shape}\")\n",
    "    # print(f\"Test data shape: {test_data.shape}\")\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = load_data(\n",
    "    TRAIN_PATH = PATHS[\"TRAIN_PATH\"],\n",
    "    TEST_PATH = PATHS[\"TEST_PATH\"],\n",
    ")\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61567ba5",
   "metadata": {
    "papermill": {
     "duration": 0.002967,
     "end_time": "2025-06-14T09:47:04.033103",
     "exception": false,
     "start_time": "2025-06-14T09:47:04.030136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedb372",
   "metadata": {
    "papermill": {
     "duration": 0.002884,
     "end_time": "2025-06-14T09:47:04.038975",
     "exception": false,
     "start_time": "2025-06-14T09:47:04.036091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Pre-processing / Feature Engineering\n",
    "\n",
    "**Pre-Processing**\n",
    "1. inf/-inf columns: `['X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', 'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716', 'X717']`\n",
    "2. columns with NaN values: `[]`\n",
    "3. 0 std columns : `['X864', 'X867', 'X869', 'X870', 'X871', 'X872']`\n",
    "\n",
    "\n",
    "**Feature Engineering**\n",
    "1. `bidask_ratio`\n",
    "2. `buysell_ratio`\n",
    "3. `bidask_delta`\n",
    "4. `buysell_delta`\n",
    "5. `buysell_size`\n",
    "6. `bidask_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6d47d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:04.046374Z",
     "iopub.status.busy": "2025-06-14T09:47:04.046065Z",
     "iopub.status.idle": "2025-06-14T09:47:04.056657Z",
     "shell.execute_reply": "2025-06-14T09:47:04.055986Z"
    },
    "papermill": {
     "duration": 0.015605,
     "end_time": "2025-06-14T09:47:04.057680",
     "exception": false,
     "start_time": "2025-06-14T09:47:04.042075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cols_inf(df: pl.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of column names that contain any positive or negative infinity.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        # df[col] is a Series; .is_infinite() → Boolean Series; .any() → Python bool\n",
    "        try:\n",
    "            if df[col].is_infinite().any():\n",
    "                cols.append(col)\n",
    "        except Exception:\n",
    "            # if the column isn’t numeric, .is_infinite() might error—just skip it\n",
    "            continue\n",
    "    return cols\n",
    "\n",
    "def get_nan_columns(df: pl.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of column names with any NaN/null values.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        if df.select(pl.col(col).is_null().any()).item():\n",
    "            cols.append(col)\n",
    "    return cols\n",
    "\n",
    "def get_cols_zerostd(df: pl.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of column names whose standard deviation is zero\n",
    "    (or whose std returns None because all values are null).\n",
    "    Non-numeric columns (e.g. datetime) are skipped.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col, dtype in zip(df.columns, df.dtypes):\n",
    "        # Only attempt std() on numeric dtypes\n",
    "        if dtype.is_numeric():  \n",
    "            # df[col] is a Series; .std() returns a Python float or None\n",
    "            std_val = df[col].std()\n",
    "            if std_val == 0.0 or std_val is None:\n",
    "                cols.append(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def feature_engineering(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Feature engineering\n",
    "    df = df.with_columns([\n",
    "        # bidask_ratio = bid_qty / ask_qty\n",
    "        (pl.col(\"bid_qty\") / pl.col(\"ask_qty\")).alias(\"bidask_ratio\"),\n",
    "\n",
    "        # buysell_ratio = 0 if volume == 0 else buy_qty / sell_qty\n",
    "        pl.when(pl.col(\"volume\") == 0)\n",
    "        .then(0)\n",
    "        .otherwise(pl.col(\"buy_qty\") / pl.col(\"sell_qty\"))\n",
    "        .alias(\"buysell_ratio\"),\n",
    "\n",
    "        # bidask_delta = bid_qty - ask_qty\n",
    "        (pl.col(\"bid_qty\") - pl.col(\"ask_qty\")).alias(\"bidask_delta\"),\n",
    "\n",
    "        # buysell_delta = buy_qty - sell_qty\n",
    "        (pl.col(\"buy_qty\") - pl.col(\"sell_qty\")).alias(\"buysell_delta\"),\n",
    "\n",
    "        # buysell_size = buy_qty + sell_qty\n",
    "        (pl.col(\"buy_qty\") + pl.col(\"sell_qty\")).alias(\"buysell_size\"),\n",
    "\n",
    "        # bidask_size = bid_qty + ask_qty\n",
    "        (pl.col(\"bid_qty\") + pl.col(\"ask_qty\")).alias(\"bidask_size\"),\n",
    "    ])\n",
    "    return df\n",
    "def preprocess_train(train: pl.DataFrame, columns_to_drop: list[str] = []) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Mirror of the original pandas workflow, but using polars.\n",
    "    1. Identify columns with infinite, NaN, or zero‐std and drop them.\n",
    "    2. Drop any user‐specified columns (e.g. label or order‐book columns).\n",
    "    3. (You can add normalized/scaling steps here if needed.)\n",
    "    \"\"\"\n",
    "    df = train.clone()\n",
    "\n",
    "    df = feature_engineering(df)\n",
    "    \n",
    "    #### Preprocessing\n",
    "    cols_inf = get_cols_inf(df)\n",
    "    print(\"Columns with infinite values:\", cols_inf)\n",
    "\n",
    "    cols_nan = get_nan_columns(df)\n",
    "    print(\"Columns with NaN values:\", cols_nan)\n",
    "\n",
    "    cols_zerostd = get_cols_zerostd(df)\n",
    "    print(\"Columns with zero standard deviation:\", cols_zerostd)\n",
    "    # Drop columns with infinite, NaN, or zero‐std values\n",
    "    drop_columns = list(set(cols_inf) | set(cols_nan) | set(cols_zerostd) | set(columns_to_drop))\n",
    "    if drop_columns:\n",
    "        df = df.drop(drop_columns)\n",
    "    # df = df.sort(\"timestamp\", descending=False)\n",
    "    return df, drop_columns\n",
    "\n",
    "def preprocess_test(test: pl.DataFrame, columns_to_drop: list[str] = []) -> pl.DataFrame:\n",
    "    df = test.clone()\n",
    "    df = feature_engineering(df)\n",
    "    df = df.drop(columns_to_drop)\n",
    "    print(\"Columns dropped from test set:\", columns_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a509a4f",
   "metadata": {
    "papermill": {
     "duration": 0.002904,
     "end_time": "2025-06-14T09:47:04.063604",
     "exception": false,
     "start_time": "2025-06-14T09:47:04.060700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2 Feature Selection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5b55b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:04.070569Z",
     "iopub.status.busy": "2025-06-14T09:47:04.070359Z",
     "iopub.status.idle": "2025-06-14T09:47:06.451895Z",
     "shell.execute_reply": "2025-06-14T09:47:06.451327Z"
    },
    "papermill": {
     "duration": 2.386721,
     "end_time": "2025-06-14T09:47:06.453211",
     "exception": false,
     "start_time": "2025-06-14T09:47:04.066490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, SelectKBest, SelectPercentile,\n",
    "    GenericUnivariateSelect, SelectFpr, SelectFdr, SelectFwe,\n",
    "    RFE, RFECV, SelectFromModel, SequentialFeatureSelector,\n",
    "    f_regression, mutual_info_regression\n",
    ")\n",
    "from sklearn.decomposition import (\n",
    "    PCA, IncrementalPCA, TruncatedSVD,\n",
    "    FastICA, SparsePCA, MiniBatchSparsePCA,\n",
    "    DictionaryLearning, MiniBatchDictionaryLearning,\n",
    "    FactorAnalysis, NMF, LatentDirichletAllocation\n",
    ")\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm.auto import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import clone\n",
    "import time\n",
    "\n",
    "class SklearnFeatureEngineeringRegression:\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.Series, use_gpu: bool = False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Predictor matrix (n_samples × P features)\n",
    "        y : pd.Series\n",
    "            Target vector (n_samples,)\n",
    "        \"\"\"\n",
    "        self.X = X.copy()\n",
    "        self.y = y.copy()\n",
    "        self.X_np = X.to_numpy()\n",
    "        self.y_np = y.to_numpy()\n",
    "        self.features = X.columns.tolist()\n",
    "        self.results_df: pd.DataFrame = pd.DataFrame()\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        # … your import logic deciding CPU vs GPU …\n",
    "        if self.use_gpu:\n",
    "            print(\"*\" * 20 + \"GPU \" * 5 + \"*\" * 20)\n",
    "            import cupy as cp\n",
    "            self.X_np = cp.asarray(self.X_np)\n",
    "            self.y_np = cp.asarray(self.y_np)\n",
    "            self.tree_model = XGBRegressor(\n",
    "                tree_method =\"hist\", device=\"cuda\",\n",
    "                n_estimators=10, max_depth=10,\n",
    "                learning_rate=0.1, random_state=42, n_jobs=-1\n",
    "            )\n",
    "            print(f\"... Fitting {self.tree_model.__class__.__name__} on {self.X.shape[0]} rows and {self.X.shape[1]} features.\")\n",
    "            self.tree_model.fit(self.X_np, self.y_np)\n",
    "        else:\n",
    "            print(f\"No Tree Model Initiated\")\n",
    "            self.tree_model = None\n",
    "        # else:\n",
    "        #     print(\"*\" * 20 + \"CPU \" * 5 + \"*\" * 20)\n",
    "        #     self.tree_model = XGBRegressor(\n",
    "        #         tree_method=\"hist\", n_estimators=10, max_depth=10,\n",
    "        #         learning_rate=0.05, random_state=42, n_jobs=-1\n",
    "        #     )\n",
    "        print(f\"\"\"SklearnFeatureEngineering Instantiated\"\"\")\n",
    "\n",
    "\n",
    "    # ---------- Filter methods ----------\n",
    "    # VarianceThreshold is a filter method that removes features with low variance.\n",
    "    def _variance_threshold(self, thresh: float = 0.0) -> pd.Series:\n",
    "        sel = VarianceThreshold(threshold=thresh).fit(self.X)\n",
    "        return pd.Series(sel.get_support(), index=self.features).astype(int)\n",
    "    # SelectKBest and SelectPercentile are filter methods that select features based on univariate statistical tests.\n",
    "    def _select_kbest_freg(self, k: int = 10) -> pd.Series:\n",
    "        sel = SelectKBest(score_func=f_regression, k=min(k, self.X.shape[1]))\n",
    "        return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "    def _select_kbest_mutualinfo(self, k: int = 10) -> pd.Series:\n",
    "        sel = SelectKBest(score_func=mutual_info_regression, k=min(k, self.X.shape[1]))\n",
    "        return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "    def _select_percentile_freg(self, p: float = 10) -> pd.Series:\n",
    "        sel = SelectPercentile(score_func=f_regression, percentile=min(p, 100))\n",
    "        return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "    def _select_percentile_mutualinfo(self, p: float = 10) -> pd.Series:\n",
    "        sel = SelectPercentile(score_func=mutual_info_regression, percentile=min(p, 100))\n",
    "        return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "    # # GenericUnivariateSelect is a filter method that allows for more flexible selection criteria.\n",
    "    # def _generic_univariate(self, k: int = 10) -> pd.Series:\n",
    "    #     sel = GenericUnivariateSelect(score_func=f_regression, mode='k_best', param=min(k, self.X.shape[1]))\n",
    "    #     return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "\n",
    "    def _select_fpr_freg(self, alpha: float = 0.05) -> pd.Series:\n",
    "        sel = SelectFpr(score_func=f_regression, alpha=alpha)\n",
    "        return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "\n",
    "    def _select_fdr_freg(self, alpha: float = 0.05) -> pd.Series:\n",
    "        sel = SelectFdr(score_func=f_regression, alpha=alpha)\n",
    "        return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "\n",
    "    def _select_fwe_freg(self, alpha: float = 0.05) -> pd.Series:\n",
    "        sel = SelectFwe(score_func=f_regression, alpha=alpha)\n",
    "        return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "\n",
    "    # ---------- Wrapper and Embedded methods ----------\n",
    "    # def _rfe_lasso(self, n_features: int = 10) -> pd.Series:\n",
    "    #     estimator = LassoCV(cv=5, max_iter=5000).fit(self.X, self.y)\n",
    "    #     sel = RFE(estimator, n_features_to_select=min(n_features, self.X.shape[1]))\n",
    "    #     return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "\n",
    "    # def _rfecv_lasso(self) -> pd.Series:\n",
    "    #     estimator = LassoCV(cv=5, max_iter=5000).fit(self.X, self.y)\n",
    "    #     sel = RFECV(estimator, cv=5)\n",
    "    #     return pd.Series(sel.fit(self.X, self.y).get_support(), index=self.features).astype(int)\n",
    "\n",
    "    def _rfe_xgb(self, n_features: int = 10) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Recursive Feature Elimination with a fresh clone of self.tree_model.\n",
    "        \"\"\"\n",
    "        # clone preserves GPU/CPU config + hyper‐parameters\n",
    "        estimator = clone(self.tree_model)\n",
    "        sel = RFE(estimator, n_features_to_select=min(n_features, self.X.shape[1]))\n",
    "        \n",
    "        X_fit = self.X_np.get() if self.use_gpu else self.X_np\n",
    "        y_fit = self.y_np.get() if self.use_gpu else self.y_np\n",
    "\n",
    "        mask = sel.fit(X_fit, y_fit).get_support()\n",
    "        return pd.Series(mask.astype(int), index=self.features).astype(int)\n",
    "\n",
    "    def _rfecv_xgb(self, cv: int = 5) -> pd.Series:\n",
    "        \"\"\"\n",
    "        RFECV with a fresh clone of self.tree_model.\n",
    "        \"\"\"\n",
    "        estimator = clone(self.tree_model)\n",
    "        sel = RFECV(estimator, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "        \n",
    "        X_fit = self.X_np.get() if self.use_gpu else self.X_np\n",
    "        y_fit = self.y_np.get() if self.use_gpu else self.y_np\n",
    "        \n",
    "        mask = sel.fit(X_fit, y_fit).get_support()\n",
    "        return pd.Series(mask.astype(int), index=self.features).astype(int)\n",
    "    \n",
    "    def _select_from_model_tree(self, threshold=\"median\") -> pd.Series:\n",
    "        \"\"\"\n",
    "        Uses the pre‐fitted self.tree_model via prefit=True.\n",
    "        \"\"\"\n",
    "        sel = SelectFromModel(self.tree_model, threshold=threshold, prefit=True)\n",
    "        mask = sel.get_support()\n",
    "        return pd.Series(mask.astype(int), index=self.features)\n",
    "\n",
    "    def _sequential_tree(\n",
    "        self,\n",
    "        n_features: int = 10,\n",
    "        direction: str = \"forward\",\n",
    "        cv: int = 5,\n",
    "        n_jobs: int = -1\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        SequentialFeatureSelector with XGBRegressor.\n",
    "\n",
    "        - Clones self.tree_model to preserve GPU/CPU config.\n",
    "        - direction: 'forward' or 'backward'\n",
    "        - cv: number of cross‐validation folds\n",
    "        - n_jobs: parallel jobs for CV\n",
    "        \"\"\"\n",
    "        # ensure we don't modify the original fitted model\n",
    "        estimator = clone(self.tree_model)\n",
    "\n",
    "        sfs = SequentialFeatureSelector(\n",
    "            estimator,\n",
    "            n_features_to_select=min(n_features, self.X.shape[1]),\n",
    "            direction=direction,\n",
    "            cv=cv,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "        \n",
    "        X_fit = self.X_np.get() if self.use_gpu else self.X_np\n",
    "        y_fit = self.y_np.get() if self.use_gpu else self.y_np\n",
    "        \n",
    "        mask = sfs.fit(X_fit, y_fit).get_support()\n",
    "        return pd.Series(mask.astype(int), index=self.features)\n",
    "\n",
    "    # ---------- Decomposition methods ----------\n",
    "    def _pca(self, n_components: float = 10, svd_solver : str = \"covariance_eigh\") -> pd.Series:\n",
    "        pca = PCA(n_components=n_components).fit(self.X)\n",
    "        load = pd.DataFrame(pca.components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _incremental_pca(self, n_components: float = 10) -> pd.Series:\n",
    "        ipca = IncrementalPCA(n_components=n_components)\n",
    "        load = pd.DataFrame(ipca.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _truncated_svd(self, n_components: int = 10) -> pd.Series:\n",
    "        k = min(n_components, self.X.shape[1])\n",
    "        ts = TruncatedSVD(n_components=k)\n",
    "        load = pd.DataFrame(ts.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _fast_ica(self, n_components: int = 10) -> pd.Series:\n",
    "        ic = FastICA(n_components=min(n_components, self.X.shape[1]), max_iter=200)\n",
    "        load = pd.DataFrame(ic.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _sparse_pca(self, n_components: int = 10) -> pd.Series:\n",
    "        spca = SparsePCA(n_components=min(n_components, self.X.shape[1]), alpha=1, max_iter=1000)\n",
    "        load = pd.DataFrame(spca.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _minibatch_sparse_pca(self, n_components: int = 10) -> pd.Series:\n",
    "        mbspca = MiniBatchSparsePCA(n_components=min(n_components, self.X.shape[1]), alpha=1)\n",
    "        load = pd.DataFrame(mbspca.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _dict_learning(self, n_components: int = 10) -> pd.Series:\n",
    "        dl = DictionaryLearning(n_components=min(n_components, self.X.shape[1]), alpha=1, max_iter=1000)\n",
    "        load = pd.DataFrame(dl.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _minibatch_dict_learning(self, n_components: int = 10) -> pd.Series:\n",
    "        mbdl = MiniBatchDictionaryLearning(n_components=min(n_components, self.X.shape[1]), alpha=1)\n",
    "        load = pd.DataFrame(mbdl.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _factor_analysis(self, n_components: int = 10) -> pd.Series:\n",
    "        fa = FactorAnalysis(n_components=min(n_components, self.X.shape[1]))\n",
    "        load = pd.DataFrame(fa.fit(self.X).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _nmf(self, n_components: int = 10) -> pd.Series:\n",
    "        nmf = NMF(n_components=min(n_components, self.X.shape[1]), init='nndsvda', max_iter=500)\n",
    "        data_pos = self.X.clip(lower=0)\n",
    "        load = pd.DataFrame(nmf.fit(data_pos).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    def _lda(self, n_components: int = 10) -> pd.Series:\n",
    "        lda = LatentDirichletAllocation(n_components=min(n_components, self.X.shape[1]), max_iter=5)\n",
    "        data_pos = self.X.clip(lower=0)\n",
    "        load = pd.DataFrame(lda.fit(data_pos).components_.T, index=self.features)\n",
    "        thresh = load.abs().mean().mean()\n",
    "        return (load.abs().max(axis=1) >= thresh).astype(int)\n",
    "\n",
    "    # ---- Random projections ----\n",
    "    def _gaussian_random_projection(self, n_components: int = 10) -> pd.Series:\n",
    "        rp = GaussianRandomProjection(n_components=min(n_components, self.X.shape[1]))\n",
    "        comp = pd.DataFrame(rp.fit(self.X).components_.T, index=self.features)\n",
    "        return self._decomp_mask(comp)\n",
    "\n",
    "    def _sparse_random_projection(self, n_components: int = 10) -> pd.Series:\n",
    "        srp = SparseRandomProjection(n_components=min(n_components, self.X.shape[1]))\n",
    "        comp = pd.DataFrame(srp.fit(self.X).components_.T, index=self.features)\n",
    "        return self._decomp_mask(comp)\n",
    "\n",
    "    # ---- Feature grouping ----\n",
    "    def _feature_agglomeration(self, n_clusters: int = 10) -> pd.Series:\n",
    "        # Fit agglomeration on the array\n",
    "        agg = FeatureAgglomeration(n_clusters=min(n_clusters, self.X.shape[1]))\n",
    "        agg.fit(self.X)\n",
    "        labels       = agg.labels_\n",
    "        cluster_data = agg.transform(self.X)\n",
    "\n",
    "        # Build a temporary DataFrame for cluster components\n",
    "        df_clust = pd.DataFrame(\n",
    "            cluster_data,\n",
    "            columns=[f\"clus_{i}\" for i in range(cluster_data.shape[1])],\n",
    "            index=self.X.index\n",
    "        )\n",
    "\n",
    "        # For each cluster, pick the feature with highest corr to its component\n",
    "        mask = pd.Series(0, index=self.features)\n",
    "        for j in range(cluster_data.shape[1]):\n",
    "            members = [f for f, l in zip(self.features, labels) if l == j]\n",
    "            corrs   = self.X[members].corrwith(df_clust.iloc[:, j]).abs()\n",
    "            mask[corrs.idxmax()] = 1\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def run(self, methods=None) -> None:\n",
    "        \"\"\"\n",
    "        Execute each selection/decomposition method with a progress bar,\n",
    "        accepting either:\n",
    "          - a dict mapping method names to parameter dicts, or\n",
    "          - a list of method names (no parameters).\n",
    "\n",
    "        Assembles `results_df` with columns ['model', features..., 'total_score'].\n",
    "        \"\"\"\n",
    "        # default methods with default params\n",
    "        default_list = [\n",
    "            '_variance_threshold',\n",
    "            '_select_kbest_freg','_select_percentile_freg',\n",
    "            '_select_kbest_mutualinfo','_select_percentile_mutualinfo',\n",
    "            '_select_fpr_freg','_select_fdr_freg','_select_fwe_freg',\n",
    "            '_rfe_xgb','_rfecv_xgb',\n",
    "            '_select_from_model_tree','_sequential_tree',\n",
    "            '_pca','_incremental_pca','_truncated_svd','_fast_ica',\n",
    "            '_sparse_pca','_minibatch_sparse_pca','_dict_learning',\n",
    "            '_minibatch_dict_learning','_factor_analysis','_nmf','_lda',\n",
    "            '_gaussian_random_projection','_sparse_random_projection',\n",
    "            '_feature_agglomeration'\n",
    "        ]\n",
    "        if methods is None:\n",
    "            methods = {m: {} for m in default_list}\n",
    "        elif isinstance(methods, list):\n",
    "            methods = {m: {} for m in methods}\n",
    "        elif not isinstance(methods, dict):\n",
    "            raise ValueError(\"`methods` must be None, list, or dict\")\n",
    "\n",
    "        records = []\n",
    "        for method_name, params in tqdm(methods.items(), desc='Running feature selection'):\n",
    "            try:\n",
    "                if not hasattr(self, method_name):\n",
    "                    raise KeyError(f\"Method {method_name} not found in class\")\n",
    "                print(f\"Running method: `{method_name.lstrip('_')}` with params: {params}\")\n",
    "                start = time.time()\n",
    "                fn = getattr(self, method_name)\n",
    "                mask = fn(**params)\n",
    "                records.append({\n",
    "                    'model': method_name.lstrip('_'),\n",
    "                    **mask.to_dict(),\n",
    "                    'total_score': int(mask.sum())\n",
    "                })\n",
    "                elapsed = time.time() - start\n",
    "                print(\n",
    "                    f\"Function `{method_name.lstrip('_')}` completed \"\n",
    "                    f\"in {elapsed/60:.2f} minutes.\"\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error running method `{method_name}`: {e}\")\n",
    "\n",
    "        self.results_df = pd.DataFrame.from_records(records)\n",
    "\n",
    "    def get_results(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the raw selection matrix (n_models × (P + 2)).\"\"\"\n",
    "        return self.results_df\n",
    "\n",
    "    def get_top_features(self, N: int = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Aggregate across models (vote count = sum of 1’s per feature),\n",
    "        and return the top N feature names.\n",
    "        \"\"\"\n",
    "        N = N or self.X.shape[1]  # Default to all features if N is None\n",
    "        return pd.DataFrame(self.results_df.loc[:, self.features].sum().sort_values(ascending=False), columns=['score']).head(N).reset_index().rename(columns={\"index\" : \"feature\"})\n",
    "\n",
    "    def get_model_featuresincluded(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with number of features included per model.\n",
    "        \"\"\"\n",
    "        model_features = self.results_df.set_index(\"model\").sum(axis=1).reset_index()\n",
    "        model_features.columns = [\"model\", \"features_included\"]\n",
    "        return model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa33126",
   "metadata": {
    "papermill": {
     "duration": 0.002875,
     "end_time": "2025-06-14T09:47:06.459413",
     "exception": false,
     "start_time": "2025-06-14T09:47:06.456538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df21d552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:06.466732Z",
     "iopub.status.busy": "2025-06-14T09:47:06.466284Z",
     "iopub.status.idle": "2025-06-14T09:47:07.471596Z",
     "shell.execute_reply": "2025-06-14T09:47:07.470694Z"
    },
    "papermill": {
     "duration": 1.010617,
     "end_time": "2025-06-14T09:47:07.472897",
     "exception": false,
     "start_time": "2025-06-14T09:47:06.462280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with infinite values: ['X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', 'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716', 'X717']\n",
      "Columns with NaN values: []\n",
      "Columns with zero standard deviation: ['X864', 'X867', 'X869', 'X870', 'X871', 'X872']\n",
      "shape: (261_428, 871)\n",
      "┌─────────┬──────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬───────────┐\n",
      "│ volume  ┆ X1       ┆ X2        ┆ X3       ┆ … ┆ bidask_del ┆ buysell_de ┆ buysell_si ┆ bidask_si │\n",
      "│ ---     ┆ ---      ┆ ---       ┆ ---      ┆   ┆ ta         ┆ lta        ┆ ze         ┆ ze        │\n",
      "│ f64     ┆ f64      ┆ f64       ┆ f64      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---       │\n",
      "│         ┆          ┆           ┆          ┆   ┆ f64        ┆ f64        ┆ f64        ┆ f64       │\n",
      "╞═════════╪══════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n",
      "│ 73.217  ┆ 1.357401 ┆ 1.434012  ┆ 2.19012  ┆ … ┆ -3.805     ┆ 17.921     ┆ 73.217     ┆ 12.663    │\n",
      "│ 490.209 ┆ 1.202742 ┆ 1.022449  ┆ 1.82013  ┆ … ┆ 5.264      ┆ 122.097    ┆ 490.209    ┆ 14.064    │\n",
      "│ 154.041 ┆ 1.189392 ┆ 0.905225  ┆ 1.735577 ┆ … ┆ 6.69       ┆ 74.831     ┆ 154.041    ┆ 8.096     │\n",
      "│ 424.449 ┆ 0.605977 ┆ -0.237821 ┆ 0.550401 ┆ … ┆ 9.206      ┆ 329.651    ┆ 424.449    ┆ 13.304    │\n",
      "│ 167.005 ┆ 0.729758 ┆ 0.008854  ┆ 0.772222 ┆ … ┆ 10.026     ┆ 36.531     ┆ 167.005    ┆ 26.022    │\n",
      "│ …       ┆ …        ┆ …         ┆ …        ┆ … ┆ …          ┆ …          ┆ …          ┆ …         │\n",
      "│ 94.388  ┆ 0.020155 ┆ 0.076565  ┆ 0.228994 ┆ … ┆ -2.642     ┆ -16.314    ┆ 94.388     ┆ 10.968    │\n",
      "│ 177.372 ┆ 0.016262 ┆ 0.062527  ┆ 0.214072 ┆ … ┆ -1.768     ┆ 43.03      ┆ 177.372    ┆ 6.348     │\n",
      "│ 101.252 ┆ 0.045407 ┆ 0.109834  ┆ 0.263577 ┆ … ┆ 1.597      ┆ 39.746     ┆ 101.252    ┆ 8.877     │\n",
      "│ 74.56   ┆ 0.124783 ┆ 0.244168  ┆ 0.408704 ┆ … ┆ 0.83       ┆ -29.83     ┆ 74.56      ┆ 10.632    │\n",
      "│ 303.722 ┆ 0.368659 ┆ 0.665382  ┆ 0.867538 ┆ … ┆ 0.06       ┆ -130.552   ┆ 303.722    ┆ 7.79      │\n",
      "└─────────┴──────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "duration = \"last_6m\"\n",
    "\n",
    "train_data_filtered = train_data.filter(\n",
    "    pl.col(\"timestamp\") >= train_splits[duration]\n",
    ")\n",
    "\n",
    "y = train_data_filtered[\"label\"]\n",
    "X, drop_columns = preprocess_train(\n",
    "    train_data_filtered,\n",
    "    columns_to_drop=[\"label\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    ")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f262bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:07.480719Z",
     "iopub.status.busy": "2025-06-14T09:47:07.480163Z",
     "iopub.status.idle": "2025-06-14T09:47:12.088511Z",
     "shell.execute_reply": "2025-06-14T09:47:12.087724Z"
    },
    "papermill": {
     "duration": 4.613312,
     "end_time": "2025-06-14T09:47:12.089734",
     "exception": false,
     "start_time": "2025-06-14T09:47:07.476422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Tree Model Initiated\n",
      "SklearnFeatureEngineering Instantiated\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c05f44aa194f72891064b2d95c27a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running feature selection:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running method: `variance_threshold` with params: {'thresh': 0.8}\n",
      "Function `variance_threshold` completed in 0.04 minutes.\n"
     ]
    }
   ],
   "source": [
    "cpu_methods = {\n",
    "    '_variance_threshold':             {'thresh': 0.8},\n",
    "    # '_select_kbest_freg':              {'k': 30},\n",
    "    # '_select_kbest_mutualinfo':        {'k': 30},\n",
    "    # '_select_percentile_freg':         {'p': 10},\n",
    "    # '_select_percentile_mutualinfo':   {'p': 10},\n",
    "    # '_select_fpr_freg':                {'alpha': 0.05},\n",
    "    # '_select_fdr_freg':                {'alpha': 0.05},\n",
    "    # '_select_fwe_freg':                {'alpha': 0.05},\n",
    "    # '_pca':                            {'n_components': 0.95},\n",
    "    # '_incremental_pca':                {'n_components': 87},\n",
    "    # '_truncated_svd':                  {'n_components': 87},\n",
    "    # '_fast_ica':                       {'n_components': 87},\n",
    "    # '_sparse_pca':                     {'n_components': 87},\n",
    "    # '_minibatch_sparse_pca':           {'n_components': 87},\n",
    "    # '_dict_learning':                  {'n_components': 87},\n",
    "    # '_minibatch_dict_learning':        {'n_components': 87},\n",
    "    # '_factor_analysis':                {'n_components': 87},\n",
    "    # '_nmf':                            {'n_components': 50},\n",
    "    # '_lda':                            {'n_components': 50},\n",
    "    # '_gaussian_random_projection':     {'n_components': 174},\n",
    "    # '_sparse_random_projection':       {'n_components': 174},\n",
    "    # '_feature_agglomeration':          {'n_clusters': 30},\n",
    "}\n",
    "\n",
    "gpu_methods = {\n",
    "    '_rfe_xgb':                        {'n_features': 30},\n",
    "    '_rfecv_xgb':                      {'cv': 10},\n",
    "    '_select_from_model_tree':         {'threshold': 'median'},\n",
    "    '_sequential_tree':                {\n",
    "        'n_features': 30,\n",
    "        'direction': 'forward',\n",
    "        'cv': 10,\n",
    "        'n_jobs': -1\n",
    "    },\n",
    "}\n",
    "\n",
    "fe_regression = SklearnFeatureEngineeringRegression(\n",
    "    X = X.drop([\"timestamp\"]).to_pandas(),\n",
    "    y = y.to_pandas(),\n",
    "    use_gpu=False  # Set to True if you want to use GPU\n",
    ")\n",
    "fe_regression.run(methods=cpu_methods)\n",
    "# fe_regression.run(methods=[\"_variance_threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f7cd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:12.097888Z",
     "iopub.status.busy": "2025-06-14T09:47:12.097322Z",
     "iopub.status.idle": "2025-06-14T09:47:12.120911Z",
     "shell.execute_reply": "2025-06-14T09:47:12.120236Z"
    },
    "papermill": {
     "duration": 0.028699,
     "end_time": "2025-06-14T09:47:12.122049",
     "exception": false,
     "start_time": "2025-06-14T09:47:12.093350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>volume</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X888</th>\n",
       "      <th>X889</th>\n",
       "      <th>X890</th>\n",
       "      <th>bidask_ratio</th>\n",
       "      <th>buysell_ratio</th>\n",
       "      <th>bidask_delta</th>\n",
       "      <th>buysell_delta</th>\n",
       "      <th>buysell_size</th>\n",
       "      <th>bidask_size</th>\n",
       "      <th>total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>variance_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 872 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  volume  X1  X2  X3  X4  X5  X6  X7  X8  ...  X888  \\\n",
       "0  variance_threshold       1   0   0   0   1   0   0   0   0  ...     0   \n",
       "\n",
       "   X889  X890  bidask_ratio  buysell_ratio  bidask_delta  buysell_delta  \\\n",
       "0     0     0             1              1             1              1   \n",
       "\n",
       "   buysell_size  bidask_size  total_score  \n",
       "0             1            1           86  \n",
       "\n",
       "[1 rows x 872 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_regression.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1a1c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:12.130069Z",
     "iopub.status.busy": "2025-06-14T09:47:12.129863Z",
     "iopub.status.idle": "2025-06-14T09:47:12.141316Z",
     "shell.execute_reply": "2025-06-14T09:47:12.140801Z"
    },
    "papermill": {
     "duration": 0.016687,
     "end_time": "2025-06-14T09:47:12.142369",
     "exception": false,
     "start_time": "2025-06-14T09:47:12.125682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features_included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>variance_threshold</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  features_included\n",
       "0  variance_threshold                172"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_regression.get_model_featuresincluded().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b80e982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:12.150201Z",
     "iopub.status.busy": "2025-06-14T09:47:12.149996Z",
     "iopub.status.idle": "2025-06-14T09:47:12.160544Z",
     "shell.execute_reply": "2025-06-14T09:47:12.159777Z"
    },
    "papermill": {
     "duration": 0.015678,
     "end_time": "2025-06-14T09:47:12.161574",
     "exception": false,
     "start_time": "2025-06-14T09:47:12.145896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>X684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  score\n",
       "0     X633      1\n",
       "1     X250      1\n",
       "2     X256      1\n",
       "3     X258      1\n",
       "4     X621      1\n",
       "5     X262      1\n",
       "6     X263      1\n",
       "7     X618      1\n",
       "8     X820      1\n",
       "9     X615      1\n",
       "10    X610      1\n",
       "11    X608      1\n",
       "12    X606      1\n",
       "13    X604      1\n",
       "14    X601      1\n",
       "15    X599      1\n",
       "16    X597      1\n",
       "17    X616      1\n",
       "18    X687      1\n",
       "19    X684      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_regression.get_top_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a328c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T09:47:12.169785Z",
     "iopub.status.busy": "2025-06-14T09:47:12.169451Z",
     "iopub.status.idle": "2025-06-14T09:47:12.817670Z",
     "shell.execute_reply": "2025-06-14T09:47:12.817092Z"
    },
    "papermill": {
     "duration": 0.654185,
     "end_time": "2025-06-14T09:47:12.819442",
     "exception": false,
     "start_time": "2025-06-14T09:47:12.165257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.environ.get(\"USER\"):\n",
    "    fe_regression.results_df.to_excel(f\"./kaggle/working/fe_results_{duration}.xlsx\", index = False)\n",
    "    fe_regression.get_top_features().to_excel(\n",
    "        f\"./kaggle/working/top_features_{duration}.xlsx\", index = True\n",
    "    )\n",
    "    fe_regression.get_model_featuresincluded().to_excel(f\"./kaggle/working/model_rank_{duration}.xlsx\", index = False)\n",
    "else:\n",
    "    fe_regression.results_df.to_excel(f\"/kaggle/working/fe_results_{duration}.xlsx\", index=False)\n",
    "    fe_regression.get_top_features().to_excel(\n",
    "        f\"/kaggle/working/top_features_{duration}.xlsx\", index=True\n",
    "    )\n",
    "    fe_regression.get_model_featuresincluded().to_excel(f\"/kaggle/working/model_rank_{duration}.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11418275,
     "sourceId": 96164,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.201246,
   "end_time": "2025-06-14T09:47:14.445360",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T09:46:30.244114",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2599bd7b48214e508f93a5e79ea1ceef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_75698719f2a04544bc1a8298eb35e67a",
       "placeholder": "​",
       "style": "IPY_MODEL_a19911a5a12c4a7bbca59b8c67a96d91",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:02&lt;00:00,  2.60s/it]"
      }
     },
     "474492cd26674fe99151aed3f1aa685d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_94b565876b84499aa9174e8942bc4925",
       "placeholder": "​",
       "style": "IPY_MODEL_688dc3eb3a634f5ebdb4c5a81183c7ad",
       "tabbable": null,
       "tooltip": null,
       "value": "Running feature selection: 100%"
      }
     },
     "5f0f6c8f5567406fa03dc7a6c96830a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "62c05f44aa194f72891064b2d95c27a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_474492cd26674fe99151aed3f1aa685d",
        "IPY_MODEL_64770f3066234ad68e38aea32693255c",
        "IPY_MODEL_2599bd7b48214e508f93a5e79ea1ceef"
       ],
       "layout": "IPY_MODEL_e16e510cc9894861888a989b824a8b00",
       "tabbable": null,
       "tooltip": null
      }
     },
     "64770f3066234ad68e38aea32693255c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f9fb516ac3e74015b903e44113d5ddd3",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5f0f6c8f5567406fa03dc7a6c96830a1",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "688dc3eb3a634f5ebdb4c5a81183c7ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75698719f2a04544bc1a8298eb35e67a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "94b565876b84499aa9174e8942bc4925": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a19911a5a12c4a7bbca59b8c67a96d91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e16e510cc9894861888a989b824a8b00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9fb516ac3e74015b903e44113d5ddd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
