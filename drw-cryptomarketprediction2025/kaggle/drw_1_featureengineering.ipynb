{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97177ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:21.218055Z",
     "iopub.status.busy": "2025-06-10T09:24:21.217784Z",
     "iopub.status.idle": "2025-06-10T09:24:21.226161Z",
     "shell.execute_reply": "2025-06-10T09:24:21.225366Z"
    },
    "papermill": {
     "duration": 0.014749,
     "end_time": "2025-06-10T09:24:21.227268",
     "exception": false,
     "start_time": "2025-06-10T09:24:21.212519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\n",
      "/kaggle/input/drw-crypto-market-prediction/train.parquet\n",
      "/kaggle/input/drw-crypto-market-prediction/test.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5f513",
   "metadata": {
    "papermill": {
     "duration": 0.003305,
     "end_time": "2025-06-10T09:24:21.234390",
     "exception": false,
     "start_time": "2025-06-10T09:24:21.231085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DRW - Crypto Market Prediction\n",
    "\n",
    "This notebook documents all the steps done in this project.\n",
    "\n",
    "Timeline:\n",
    "- 10/06/25: 0.05031\n",
    "    - Reorganize notebooks.\n",
    "    - Test training with GPU - Way faster than CPU.\n",
    "    - Implement feature elimination using GPU.\n",
    "    - Tested with Linear Models - will be extremely slow in iteration.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47bb523c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:21.242295Z",
     "iopub.status.busy": "2025-06-10T09:24:21.241877Z",
     "iopub.status.idle": "2025-06-10T09:24:23.208665Z",
     "shell.execute_reply": "2025-06-10T09:24:23.208062Z"
    },
    "papermill": {
     "duration": 1.972265,
     "end_time": "2025-06-10T09:24:23.209990",
     "exception": false,
     "start_time": "2025-06-10T09:24:21.237725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13578b19",
   "metadata": {
    "papermill": {
     "duration": 0.002952,
     "end_time": "2025-06-10T09:24:23.216308",
     "exception": false,
     "start_time": "2025-06-10T09:24:23.213356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1490b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:23.223572Z",
     "iopub.status.busy": "2025-06-10T09:24:23.223185Z",
     "iopub.status.idle": "2025-06-10T09:24:36.347047Z",
     "shell.execute_reply": "2025-06-10T09:24:36.346297Z"
    },
    "papermill": {
     "duration": 13.128834,
     "end_time": "2025-06-10T09:24:36.348269",
     "exception": false,
     "start_time": "2025-06-10T09:24:23.219435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (525_887, 897)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>bid_qty</th><th>ask_qty</th><th>buy_qty</th><th>sell_qty</th><th>volume</th><th>X1</th><th>X2</th><th>X3</th><th>X4</th><th>X5</th><th>X6</th><th>X7</th><th>X8</th><th>X9</th><th>X10</th><th>X11</th><th>X12</th><th>X13</th><th>X14</th><th>X15</th><th>X16</th><th>X17</th><th>X18</th><th>X19</th><th>X20</th><th>X21</th><th>X22</th><th>X23</th><th>X24</th><th>X25</th><th>X26</th><th>X27</th><th>X28</th><th>X29</th><th>X30</th><th>X31</th><th>X32</th><th>&hellip;</th><th>X856</th><th>X857</th><th>X858</th><th>X859</th><th>X860</th><th>X861</th><th>X862</th><th>X863</th><th>X864</th><th>X865</th><th>X866</th><th>X867</th><th>X868</th><th>X869</th><th>X870</th><th>X871</th><th>X872</th><th>X873</th><th>X874</th><th>X875</th><th>X876</th><th>X877</th><th>X878</th><th>X879</th><th>X880</th><th>X881</th><th>X882</th><th>X883</th><th>X884</th><th>X885</th><th>X886</th><th>X887</th><th>X888</th><th>X889</th><th>X890</th><th>label</th><th>timestamp</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>datetime[ns]</td></tr></thead><tbody><tr><td>15.283</td><td>8.425</td><td>176.405</td><td>44.984</td><td>221.389</td><td>0.121263</td><td>-0.41769</td><td>0.005399</td><td>0.125948</td><td>0.058359</td><td>0.027359</td><td>0.03578</td><td>0.068219</td><td>1.034825</td><td>-0.029575</td><td>0.327805</td><td>0.485823</td><td>0.668596</td><td>0.617389</td><td>0.770037</td><td>0.857631</td><td>1.754456</td><td>0.572503</td><td>0.883229</td><td>0.58567</td><td>0.816321</td><td>0.529973</td><td>0.508244</td><td>0.448616</td><td>1.341892</td><td>1.406392</td><td>0.953631</td><td>1.183991</td><td>1.474789</td><td>0.774389</td><td>0.660586</td><td>0.269043</td><td>&hellip;</td><td>-0.216525</td><td>0.200508</td><td>0.492433</td><td>-0.51249</td><td>0.541286</td><td>-0.336399</td><td>-1.027483</td><td>0.21857</td><td>0.0</td><td>1.728155</td><td>0.62414</td><td>0.0</td><td>-0.051211</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.691754</td><td>0.242124</td><td>2.096157</td><td>3.369195</td><td>0.244667</td><td>0.286611</td><td>0.722679</td><td>0.901931</td><td>1.000007</td><td>1.925423</td><td>1.847943</td><td>0.005676</td><td>0.190791</td><td>0.369691</td><td>0.37763</td><td>0.210153</td><td>0.159183</td><td>0.530636</td><td>0.562539</td><td>2023-03-01 00:00:00</td></tr><tr><td>38.59</td><td>2.336</td><td>525.846</td><td>321.95</td><td>847.796</td><td>0.302841</td><td>-0.049576</td><td>0.356667</td><td>0.481087</td><td>0.237954</td><td>0.208359</td><td>0.217057</td><td>0.249624</td><td>0.948694</td><td>-0.183488</td><td>0.150526</td><td>0.308421</td><td>0.492232</td><td>0.529787</td><td>0.682958</td><td>0.770965</td><td>1.686504</td><td>0.273357</td><td>0.591695</td><td>0.442391</td><td>0.674792</td><td>0.460741</td><td>0.439681</td><td>0.380399</td><td>1.304113</td><td>1.003783</td><td>0.776628</td><td>1.015943</td><td>1.312735</td><td>0.696895</td><td>0.584217</td><td>0.231104</td><td>&hellip;</td><td>-0.180112</td><td>0.213252</td><td>0.479806</td><td>-0.180527</td><td>0.450331</td><td>-0.31915</td><td>-1.024055</td><td>0.088014</td><td>0.0</td><td>1.665698</td><td>0.622775</td><td>0.0</td><td>-0.079621</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.691665</td><td>0.242091</td><td>2.46103</td><td>4.127584</td><td>0.321394</td><td>0.31246</td><td>0.746452</td><td>0.912371</td><td>1.003153</td><td>1.928569</td><td>1.849468</td><td>0.005227</td><td>0.18466</td><td>0.363642</td><td>0.374515</td><td>0.209573</td><td>0.158963</td><td>0.530269</td><td>0.533686</td><td>2023-03-01 00:01:00</td></tr><tr><td>0.442</td><td>60.25</td><td>159.227</td><td>136.369</td><td>295.596</td><td>0.167462</td><td>-0.291212</td><td>0.083138</td><td>0.206881</td><td>0.101727</td><td>0.072778</td><td>0.081564</td><td>0.114166</td><td>0.896459</td><td>-0.261779</td><td>0.044571</td><td>0.200608</td><td>0.384558</td><td>0.476229</td><td>0.629848</td><td>0.718232</td><td>1.656707</td><td>0.140156</td><td>0.457268</td><td>0.376524</td><td>0.610116</td><td>0.429751</td><td>0.409316</td><td>0.350359</td><td>1.28325</td><td>0.760801</td><td>0.670816</td><td>0.917205</td><td>1.219124</td><td>0.653355</td><td>0.541739</td><td>0.210095</td><td>&hellip;</td><td>-0.265966</td><td>0.191734</td><td>0.440207</td><td>-0.108209</td><td>0.420681</td><td>-0.316953</td><td>-1.024056</td><td>-0.147363</td><td>0.0</td><td>1.666893</td><td>0.621414</td><td>0.0</td><td>-0.080427</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.691674</td><td>0.242093</td><td>2.493249</td><td>4.182112</td><td>0.326701</td><td>0.314636</td><td>0.746681</td><td>0.911129</td><td>1.002502</td><td>1.928047</td><td>1.849282</td><td>0.004796</td><td>0.178719</td><td>0.357689</td><td>0.371424</td><td>0.208993</td><td>0.158744</td><td>0.529901</td><td>0.546505</td><td>2023-03-01 00:02:00</td></tr><tr><td>4.865</td><td>21.016</td><td>335.742</td><td>124.963</td><td>460.705</td><td>0.072944</td><td>-0.43659</td><td>-0.102483</td><td>0.017551</td><td>0.007149</td><td>-0.021681</td><td>-0.012936</td><td>0.019634</td><td>0.732634</td><td>-0.535845</td><td>-0.273947</td><td>-0.124959</td><td>0.056438</td><td>0.311539</td><td>0.465377</td><td>0.554022</td><td>1.663491</td><td>0.152084</td><td>0.468778</td><td>0.383696</td><td>0.618529</td><td>0.435326</td><td>0.415523</td><td>0.356895</td><td>1.319538</td><td>0.955549</td><td>0.789646</td><td>1.044941</td><td>1.353001</td><td>0.72392</td><td>0.613462</td><td>0.246212</td><td>&hellip;</td><td>-0.322244</td><td>0.183687</td><td>0.404295</td><td>-0.169373</td><td>0.386584</td><td>-0.314775</td><td>-1.024058</td><td>-0.09459</td><td>0.0</td><td>1.735322</td><td>0.620057</td><td>0.0</td><td>-0.094702</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.69121</td><td>0.24193</td><td>2.525526</td><td>4.292975</td><td>0.350791</td><td>0.32357</td><td>0.753829</td><td>0.913363</td><td>1.002985</td><td>1.928621</td><td>1.849608</td><td>0.004398</td><td>0.172967</td><td>0.351832</td><td>0.368358</td><td>0.208416</td><td>0.158524</td><td>0.529534</td><td>0.357703</td><td>2023-03-01 00:03:00</td></tr><tr><td>27.158</td><td>3.451</td><td>98.411</td><td>44.407</td><td>142.818</td><td>0.17382</td><td>-0.213489</td><td>0.096067</td><td>0.215709</td><td>0.107133</td><td>0.078976</td><td>0.087818</td><td>0.120426</td><td>0.763537</td><td>-0.430945</td><td>-0.205298</td><td>-0.062118</td><td>0.117266</td><td>0.341493</td><td>0.495591</td><td>0.584519</td><td>1.668419</td><td>0.156177</td><td>0.472732</td><td>0.3871</td><td>0.623192</td><td>0.439034</td><td>0.419868</td><td>0.361572</td><td>1.324595</td><td>0.90546</td><td>0.78375</td><td>1.047708</td><td>1.36188</td><td>0.732001</td><td>0.622712</td><td>0.251095</td><td>&hellip;</td><td>-0.369625</td><td>0.192377</td><td>0.415438</td><td>-0.198976</td><td>0.389969</td><td>-0.312628</td><td>-1.02406</td><td>0.162221</td><td>0.0</td><td>1.712096</td><td>0.618703</td><td>0.0</td><td>-0.091884</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.691207</td><td>0.241928</td><td>2.52443</td><td>4.306694</td><td>0.335599</td><td>0.31907</td><td>0.747533</td><td>0.908904</td><td>1.001286</td><td>1.927084</td><td>1.84895</td><td>0.004008</td><td>0.167391</td><td>0.346066</td><td>0.365314</td><td>0.207839</td><td>0.158304</td><td>0.529167</td><td>0.362452</td><td>2023-03-01 00:04:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4.163</td><td>6.805</td><td>39.037</td><td>55.351</td><td>94.388</td><td>0.020155</td><td>0.076565</td><td>0.228994</td><td>0.288856</td><td>0.151634</td><td>0.108347</td><td>0.088073</td><td>0.073729</td><td>0.071211</td><td>0.460379</td><td>0.494391</td><td>0.372694</td><td>0.270015</td><td>0.089571</td><td>0.096287</td><td>0.109409</td><td>0.78486</td><td>2.031313</td><td>1.673446</td><td>0.641512</td><td>0.772499</td><td>0.773449</td><td>0.956571</td><td>0.899399</td><td>0.477649</td><td>0.120275</td><td>0.017187</td><td>0.166928</td><td>0.519881</td><td>0.607589</td><td>0.797609</td><td>0.31223</td><td>&hellip;</td><td>0.035728</td><td>0.551648</td><td>1.233784</td><td>-0.252775</td><td>-0.040562</td><td>-0.347201</td><td>-0.21873</td><td>0.636555</td><td>0.0</td><td>0.533902</td><td>0.142461</td><td>0.0</td><td>-0.768709</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.260958</td><td>0.197249</td><td>1.776607</td><td>2.702758</td><td>0.204378</td><td>0.270656</td><td>0.750338</td><td>1.060258</td><td>1.450851</td><td>3.219345</td><td>3.340686</td><td>0.008679</td><td>0.224656</td><td>0.401595</td><td>0.393726</td><td>0.212651</td><td>0.136494</td><td>0.243172</td><td>0.396289</td><td>2024-02-29 23:55:00</td></tr><tr><td>2.29</td><td>4.058</td><td>110.201</td><td>67.171</td><td>177.372</td><td>0.016262</td><td>0.062527</td><td>0.214072</td><td>0.276463</td><td>0.146521</td><td>0.104164</td><td>0.084063</td><td>0.069788</td><td>0.024066</td><td>0.332808</td><td>0.387194</td><td>0.27384</td><td>0.174273</td><td>0.042308</td><td>0.049073</td><td>0.06222</td><td>0.811096</td><td>1.942052</td><td>1.721022</td><td>0.682607</td><td>0.818153</td><td>0.79747</td><td>0.981444</td><td>0.924992</td><td>0.496542</td><td>0.246743</td><td>0.089766</td><td>0.238524</td><td>0.590531</td><td>0.643586</td><td>0.834236</td><td>0.330893</td><td>&hellip;</td><td>0.052891</td><td>0.572652</td><td>1.236672</td><td>-0.253142</td><td>-0.027268</td><td>-0.220352</td><td>-0.206114</td><td>0.649406</td><td>0.0</td><td>0.544298</td><td>0.149768</td><td>0.0</td><td>-0.779659</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.260872</td><td>0.197186</td><td>1.807592</td><td>2.742924</td><td>0.213951</td><td>0.271922</td><td>0.748216</td><td>1.056653</td><td>1.448602</td><td>3.216719</td><td>3.339353</td><td>0.007928</td><td>0.217422</td><td>0.395019</td><td>0.390476</td><td>0.212063</td><td>0.136305</td><td>0.243004</td><td>0.328993</td><td>2024-02-29 23:56:00</td></tr><tr><td>5.237</td><td>3.64</td><td>70.499</td><td>30.753</td><td>101.252</td><td>0.045407</td><td>0.109834</td><td>0.263577</td><td>0.329266</td><td>0.174214</td><td>0.13294</td><td>0.113052</td><td>0.098865</td><td>-0.05737</td><td>0.154488</td><td>0.217087</td><td>0.10915</td><td>0.011308</td><td>-0.039019</td><td>-0.032317</td><td>-0.019202</td><td>0.498355</td><td>0.628261</td><td>0.454894</td><td>0.056188</td><td>0.191078</td><td>0.483386</td><td>0.667775</td><td>0.611826</td><td>0.458054</td><td>-0.055595</td><td>-0.062112</td><td>0.083189</td><td>0.432974</td><td>0.565042</td><td>0.756211</td><td>0.292203</td><td>&hellip;</td><td>0.024071</td><td>0.54706</td><td>1.191918</td><td>-0.342808</td><td>-0.065439</td><td>-0.220704</td><td>-0.206118</td><td>0.535593</td><td>0.0</td><td>0.498593</td><td>0.150411</td><td>0.0</td><td>-0.805622</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.260703</td><td>0.197062</td><td>1.7447</td><td>2.73189</td><td>0.210581</td><td>0.268868</td><td>0.741793</td><td>1.050909</td><td>1.445661</td><td>3.213444</td><td>3.33774</td><td>0.007243</td><td>0.210421</td><td>0.388549</td><td>0.387252</td><td>0.211477</td><td>0.136117</td><td>0.242836</td><td>0.189909</td><td>2024-02-29 23:57:00</td></tr><tr><td>5.731</td><td>4.901</td><td>22.365</td><td>52.195</td><td>74.56</td><td>0.124783</td><td>0.244168</td><td>0.408704</td><td>0.480016</td><td>0.251493</td><td>0.211727</td><td>0.19216</td><td>0.178116</td><td>0.111335</td><td>0.44718</td><td>0.53661</td><td>0.439239</td><td>0.345835</td><td>0.129327</td><td>0.136199</td><td>0.149399</td><td>0.803323</td><td>1.680122</td><td>1.620743</td><td>0.655204</td><td>0.794395</td><td>0.78617</td><td>0.971394</td><td>0.916158</td><td>0.496689</td><td>0.230439</td><td>0.089445</td><td>0.23383</td><td>0.582657</td><td>0.640532</td><td>0.832325</td><td>0.330608</td><td>&hellip;</td><td>0.035102</td><td>0.568606</td><td>1.212147</td><td>-0.369407</td><td>-0.035077</td><td>-0.221043</td><td>-0.206122</td><td>0.647059</td><td>0.0</td><td>0.528757</td><td>0.151051</td><td>0.0</td><td>-0.774165</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.260957</td><td>0.197257</td><td>1.74259</td><td>2.643514</td><td>0.203284</td><td>0.264413</td><td>0.733953</td><td>1.044452</td><td>1.442484</td><td>3.209945</td><td>3.33603</td><td>0.006608</td><td>0.203642</td><td>0.382184</td><td>0.384054</td><td>0.210892</td><td>0.135928</td><td>0.242668</td><td>0.410831</td><td>2024-02-29 23:58:00</td></tr><tr><td>3.925</td><td>3.865</td><td>86.585</td><td>217.137</td><td>303.722</td><td>0.368659</td><td>0.665382</td><td>0.867538</td><td>0.951903</td><td>0.491276</td><td>0.454342</td><td>0.435431</td><td>0.4217</td><td>0.330298</td><td>0.804642</td><td>0.9431</td><td>0.862786</td><td>0.777285</td><td>0.347325</td><td>0.354669</td><td>0.368107</td><td>1.128738</td><td>2.710711</td><td>2.828132</td><td>1.284624</td><td>1.433281</td><td>1.108506</td><td>1.295011</td><td>1.240712</td><td>0.602761</td><td>0.980926</td><td>0.497163</td><td>0.647331</td><td>0.998625</td><td>0.850315</td><td>1.043021</td><td>0.436378</td><td>&hellip;</td><td>-0.052765</td><td>0.597701</td><td>1.450874</td><td>-0.436284</td><td>0.202887</td><td>-0.221368</td><td>-0.206125</td><td>0.331538</td><td>0.0</td><td>0.669032</td><td>0.151687</td><td>0.0</td><td>-0.66805</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.261324</td><td>0.197537</td><td>1.790457</td><td>2.627113</td><td>0.232998</td><td>0.272984</td><td>0.739299</td><td>1.044576</td><td>1.441416</td><td>3.208415</td><td>3.335166</td><td>0.006072</td><td>0.197096</td><td>0.375931</td><td>0.380886</td><td>0.21031</td><td>0.135741</td><td>0.242501</td><td>0.731542</td><td>2024-02-29 23:59:00</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (525_887, 897)\n",
       "┌─────────┬─────────┬─────────┬──────────┬───┬──────────┬──────────┬──────────┬──────────────┐\n",
       "│ bid_qty ┆ ask_qty ┆ buy_qty ┆ sell_qty ┆ … ┆ X889     ┆ X890     ┆ label    ┆ timestamp    │\n",
       "│ ---     ┆ ---     ┆ ---     ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---          │\n",
       "│ f64     ┆ f64     ┆ f64     ┆ f64      ┆   ┆ f64      ┆ f64      ┆ f64      ┆ datetime[ns] │\n",
       "╞═════════╪═════════╪═════════╪══════════╪═══╪══════════╪══════════╪══════════╪══════════════╡\n",
       "│ 15.283  ┆ 8.425   ┆ 176.405 ┆ 44.984   ┆ … ┆ 0.159183 ┆ 0.530636 ┆ 0.562539 ┆ 2023-03-01   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:00:00     │\n",
       "│ 38.59   ┆ 2.336   ┆ 525.846 ┆ 321.95   ┆ … ┆ 0.158963 ┆ 0.530269 ┆ 0.533686 ┆ 2023-03-01   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:01:00     │\n",
       "│ 0.442   ┆ 60.25   ┆ 159.227 ┆ 136.369  ┆ … ┆ 0.158744 ┆ 0.529901 ┆ 0.546505 ┆ 2023-03-01   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:02:00     │\n",
       "│ 4.865   ┆ 21.016  ┆ 335.742 ┆ 124.963  ┆ … ┆ 0.158524 ┆ 0.529534 ┆ 0.357703 ┆ 2023-03-01   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:03:00     │\n",
       "│ 27.158  ┆ 3.451   ┆ 98.411  ┆ 44.407   ┆ … ┆ 0.158304 ┆ 0.529167 ┆ 0.362452 ┆ 2023-03-01   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 00:04:00     │\n",
       "│ …       ┆ …       ┆ …       ┆ …        ┆ … ┆ …        ┆ …        ┆ …        ┆ …            │\n",
       "│ 4.163   ┆ 6.805   ┆ 39.037  ┆ 55.351   ┆ … ┆ 0.136494 ┆ 0.243172 ┆ 0.396289 ┆ 2024-02-29   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:55:00     │\n",
       "│ 2.29    ┆ 4.058   ┆ 110.201 ┆ 67.171   ┆ … ┆ 0.136305 ┆ 0.243004 ┆ 0.328993 ┆ 2024-02-29   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:56:00     │\n",
       "│ 5.237   ┆ 3.64    ┆ 70.499  ┆ 30.753   ┆ … ┆ 0.136117 ┆ 0.242836 ┆ 0.189909 ┆ 2024-02-29   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:57:00     │\n",
       "│ 5.731   ┆ 4.901   ┆ 22.365  ┆ 52.195   ┆ … ┆ 0.135928 ┆ 0.242668 ┆ 0.410831 ┆ 2024-02-29   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:58:00     │\n",
       "│ 3.925   ┆ 3.865   ┆ 86.585  ┆ 217.137  ┆ … ┆ 0.135741 ┆ 0.242501 ┆ 0.731542 ┆ 2024-02-29   │\n",
       "│         ┆         ┆         ┆          ┆   ┆          ┆          ┆          ┆ 23:59:00     │\n",
       "└─────────┴─────────┴─────────┴──────────┴───┴──────────┴──────────┴──────────┴──────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.read_parquet(\n",
    "    \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    ").sort(\"timestamp\", descending = False)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d313ae",
   "metadata": {
    "papermill": {
     "duration": 0.003374,
     "end_time": "2025-06-10T09:24:36.355731",
     "exception": false,
     "start_time": "2025-06-10T09:24:36.352357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Pre-processing / Feature Engineering\n",
    "\n",
    "**Pre-Processing**\n",
    "1. inf/-inf columns: `['X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', 'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716', 'X717']`\n",
    "2. columns with NaN values: `[]`\n",
    "3. 0 std columns : `['X864', 'X867', 'X869', 'X870', 'X871', 'X872']`\n",
    "\n",
    "\n",
    "**Feature Engineering**\n",
    "1. `bidask_ratio`\n",
    "2. `buysell_ratio`\n",
    "3. `bidask_delta`\n",
    "4. `buysell_delta`\n",
    "5. `buysell_size`\n",
    "6. `bidask_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfbfe8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:36.363900Z",
     "iopub.status.busy": "2025-06-10T09:24:36.363638Z",
     "iopub.status.idle": "2025-06-10T09:24:36.374286Z",
     "shell.execute_reply": "2025-06-10T09:24:36.373512Z"
    },
    "papermill": {
     "duration": 0.016442,
     "end_time": "2025-06-10T09:24:36.375639",
     "exception": false,
     "start_time": "2025-06-10T09:24:36.359197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cols_inf(df: pl.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of column names that contain any positive or negative infinity.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        # df[col] is a Series; .is_infinite() → Boolean Series; .any() → Python bool\n",
    "        try:\n",
    "            if df[col].is_infinite().any():\n",
    "                cols.append(col)\n",
    "        except Exception:\n",
    "            # if the column isn’t numeric, .is_infinite() might error—just skip it\n",
    "            continue\n",
    "    return cols\n",
    "\n",
    "def get_nan_columns(df: pl.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of column names with any NaN/null values.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        if df.select(pl.col(col).is_null().any()).item():\n",
    "            cols.append(col)\n",
    "    return cols\n",
    "\n",
    "def get_cols_zerostd(df: pl.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of column names whose standard deviation is zero\n",
    "    (or whose std returns None because all values are null).\n",
    "    Non-numeric columns (e.g. datetime) are skipped.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col, dtype in zip(df.columns, df.dtypes):\n",
    "        # Only attempt std() on numeric dtypes\n",
    "        if dtype.is_numeric():  \n",
    "            # df[col] is a Series; .std() returns a Python float or None\n",
    "            std_val = df[col].std()\n",
    "            if std_val == 0.0 or std_val is None:\n",
    "                cols.append(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def feature_engineering(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Feature engineering\n",
    "    df = df.with_columns([\n",
    "        # bidask_ratio = bid_qty / ask_qty\n",
    "        (pl.col(\"bid_qty\") / pl.col(\"ask_qty\")).alias(\"bidask_ratio\"),\n",
    "\n",
    "        # buysell_ratio = 0 if volume == 0 else buy_qty / sell_qty\n",
    "        pl.when(pl.col(\"volume\") == 0)\n",
    "        .then(0)\n",
    "        .otherwise(pl.col(\"buy_qty\") / pl.col(\"sell_qty\"))\n",
    "        .alias(\"buysell_ratio\"),\n",
    "\n",
    "        # bidask_delta = bid_qty - ask_qty\n",
    "        (pl.col(\"bid_qty\") - pl.col(\"ask_qty\")).alias(\"bidask_delta\"),\n",
    "\n",
    "        # buysell_delta = buy_qty - sell_qty\n",
    "        (pl.col(\"buy_qty\") - pl.col(\"sell_qty\")).alias(\"buysell_delta\"),\n",
    "\n",
    "        # buysell_size = buy_qty + sell_qty\n",
    "        (pl.col(\"buy_qty\") + pl.col(\"sell_qty\")).alias(\"buysell_size\"),\n",
    "\n",
    "        # bidask_size = bid_qty + ask_qty\n",
    "        (pl.col(\"bid_qty\") + pl.col(\"ask_qty\")).alias(\"bidask_size\"),\n",
    "    ])\n",
    "    return df\n",
    "def preprocess_train(train: pl.DataFrame, columns_to_drop: list[str] = []) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Mirror of the original pandas workflow, but using polars.\n",
    "    1. Identify columns with infinite, NaN, or zero‐std and drop them.\n",
    "    2. Drop any user‐specified columns (e.g. label or order‐book columns).\n",
    "    3. (You can add normalized/scaling steps here if needed.)\n",
    "    \"\"\"\n",
    "    df = train.clone()\n",
    "\n",
    "    df = feature_engineering(df)\n",
    "    \n",
    "    #### Preprocessing\n",
    "    cols_inf = get_cols_inf(df)\n",
    "    print(\"Columns with infinite values:\", cols_inf)\n",
    "\n",
    "    cols_nan = get_nan_columns(df)\n",
    "    print(\"Columns with NaN values:\", cols_nan)\n",
    "\n",
    "    cols_zerostd = get_cols_zerostd(df)\n",
    "    print(\"Columns with zero standard deviation:\", cols_zerostd)\n",
    "    # Drop columns with infinite, NaN, or zero‐std values\n",
    "    drop_columns = list(set(cols_inf) | set(cols_nan) | set(cols_zerostd) | set(columns_to_drop))\n",
    "    if drop_columns:\n",
    "        df = df.drop(drop_columns)\n",
    "    # df = df.sort(\"timestamp\", descending=False)\n",
    "    return df, drop_columns\n",
    "\n",
    "def preprocess_test(test: pl.DataFrame, columns_to_drop: list[str] = []) -> pl.DataFrame:\n",
    "    df = test.clone()\n",
    "    df = feature_engineering(df)\n",
    "    df = df.drop(columns_to_drop)\n",
    "    print(\"Columns dropped from test set:\", columns_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cf748e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:36.383894Z",
     "iopub.status.busy": "2025-06-10T09:24:36.383660Z",
     "iopub.status.idle": "2025-06-10T09:24:38.227486Z",
     "shell.execute_reply": "2025-06-10T09:24:38.226775Z"
    },
    "papermill": {
     "duration": 1.849213,
     "end_time": "2025-06-10T09:24:38.228705",
     "exception": false,
     "start_time": "2025-06-10T09:24:36.379492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with infinite values: ['X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', 'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716', 'X717']\n",
      "Columns with NaN values: []\n",
      "Columns with zero standard deviation: ['X864', 'X867', 'X869', 'X870', 'X871', 'X872']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (525_887, 871)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>volume</th><th>X1</th><th>X2</th><th>X3</th><th>X4</th><th>X5</th><th>X6</th><th>X7</th><th>X8</th><th>X9</th><th>X10</th><th>X11</th><th>X12</th><th>X13</th><th>X14</th><th>X15</th><th>X16</th><th>X17</th><th>X18</th><th>X19</th><th>X20</th><th>X21</th><th>X22</th><th>X23</th><th>X24</th><th>X25</th><th>X26</th><th>X27</th><th>X28</th><th>X29</th><th>X30</th><th>X31</th><th>X32</th><th>X33</th><th>X34</th><th>X35</th><th>X36</th><th>&hellip;</th><th>X855</th><th>X856</th><th>X857</th><th>X858</th><th>X859</th><th>X860</th><th>X861</th><th>X862</th><th>X863</th><th>X865</th><th>X866</th><th>X868</th><th>X873</th><th>X874</th><th>X875</th><th>X876</th><th>X877</th><th>X878</th><th>X879</th><th>X880</th><th>X881</th><th>X882</th><th>X883</th><th>X884</th><th>X885</th><th>X886</th><th>X887</th><th>X888</th><th>X889</th><th>X890</th><th>timestamp</th><th>bidask_ratio</th><th>buysell_ratio</th><th>bidask_delta</th><th>buysell_delta</th><th>buysell_size</th><th>bidask_size</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>datetime[ns]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>221.389</td><td>0.121263</td><td>-0.41769</td><td>0.005399</td><td>0.125948</td><td>0.058359</td><td>0.027359</td><td>0.03578</td><td>0.068219</td><td>1.034825</td><td>-0.029575</td><td>0.327805</td><td>0.485823</td><td>0.668596</td><td>0.617389</td><td>0.770037</td><td>0.857631</td><td>1.754456</td><td>0.572503</td><td>0.883229</td><td>0.58567</td><td>0.816321</td><td>0.529973</td><td>0.508244</td><td>0.448616</td><td>1.341892</td><td>1.406392</td><td>0.953631</td><td>1.183991</td><td>1.474789</td><td>0.774389</td><td>0.660586</td><td>0.269043</td><td>0.962802</td><td>0.966513</td><td>0.952759</td><td>0.952916</td><td>&hellip;</td><td>0.418618</td><td>-0.216525</td><td>0.200508</td><td>0.492433</td><td>-0.51249</td><td>0.541286</td><td>-0.336399</td><td>-1.027483</td><td>0.21857</td><td>1.728155</td><td>0.62414</td><td>-0.051211</td><td>0.691754</td><td>0.242124</td><td>2.096157</td><td>3.369195</td><td>0.244667</td><td>0.286611</td><td>0.722679</td><td>0.901931</td><td>1.000007</td><td>1.925423</td><td>1.847943</td><td>0.005676</td><td>0.190791</td><td>0.369691</td><td>0.37763</td><td>0.210153</td><td>0.159183</td><td>0.530636</td><td>2023-03-01 00:00:00</td><td>1.814006</td><td>3.921505</td><td>6.858</td><td>131.421</td><td>221.389</td><td>23.708</td></tr><tr><td>847.796</td><td>0.302841</td><td>-0.049576</td><td>0.356667</td><td>0.481087</td><td>0.237954</td><td>0.208359</td><td>0.217057</td><td>0.249624</td><td>0.948694</td><td>-0.183488</td><td>0.150526</td><td>0.308421</td><td>0.492232</td><td>0.529787</td><td>0.682958</td><td>0.770965</td><td>1.686504</td><td>0.273357</td><td>0.591695</td><td>0.442391</td><td>0.674792</td><td>0.460741</td><td>0.439681</td><td>0.380399</td><td>1.304113</td><td>1.003783</td><td>0.776628</td><td>1.015943</td><td>1.312735</td><td>0.696895</td><td>0.584217</td><td>0.231104</td><td>0.935145</td><td>0.938957</td><td>0.918275</td><td>0.919065</td><td>&hellip;</td><td>0.424977</td><td>-0.180112</td><td>0.213252</td><td>0.479806</td><td>-0.180527</td><td>0.450331</td><td>-0.31915</td><td>-1.024055</td><td>0.088014</td><td>1.665698</td><td>0.622775</td><td>-0.079621</td><td>0.691665</td><td>0.242091</td><td>2.46103</td><td>4.127584</td><td>0.321394</td><td>0.31246</td><td>0.746452</td><td>0.912371</td><td>1.003153</td><td>1.928569</td><td>1.849468</td><td>0.005227</td><td>0.18466</td><td>0.363642</td><td>0.374515</td><td>0.209573</td><td>0.158963</td><td>0.530269</td><td>2023-03-01 00:01:00</td><td>16.519692</td><td>1.633316</td><td>36.254</td><td>203.896</td><td>847.796</td><td>40.926</td></tr><tr><td>295.596</td><td>0.167462</td><td>-0.291212</td><td>0.083138</td><td>0.206881</td><td>0.101727</td><td>0.072778</td><td>0.081564</td><td>0.114166</td><td>0.896459</td><td>-0.261779</td><td>0.044571</td><td>0.200608</td><td>0.384558</td><td>0.476229</td><td>0.629848</td><td>0.718232</td><td>1.656707</td><td>0.140156</td><td>0.457268</td><td>0.376524</td><td>0.610116</td><td>0.429751</td><td>0.409316</td><td>0.350359</td><td>1.28325</td><td>0.760801</td><td>0.670816</td><td>0.917205</td><td>1.219124</td><td>0.653355</td><td>0.541739</td><td>0.210095</td><td>0.932614</td><td>0.936476</td><td>0.919497</td><td>0.92028</td><td>&hellip;</td><td>0.409942</td><td>-0.265966</td><td>0.191734</td><td>0.440207</td><td>-0.108209</td><td>0.420681</td><td>-0.316953</td><td>-1.024056</td><td>-0.147363</td><td>1.666893</td><td>0.621414</td><td>-0.080427</td><td>0.691674</td><td>0.242093</td><td>2.493249</td><td>4.182112</td><td>0.326701</td><td>0.314636</td><td>0.746681</td><td>0.911129</td><td>1.002502</td><td>1.928047</td><td>1.849282</td><td>0.004796</td><td>0.178719</td><td>0.357689</td><td>0.371424</td><td>0.208993</td><td>0.158744</td><td>0.529901</td><td>2023-03-01 00:02:00</td><td>0.007336</td><td>1.167619</td><td>-59.808</td><td>22.858</td><td>295.596</td><td>60.692</td></tr><tr><td>460.705</td><td>0.072944</td><td>-0.43659</td><td>-0.102483</td><td>0.017551</td><td>0.007149</td><td>-0.021681</td><td>-0.012936</td><td>0.019634</td><td>0.732634</td><td>-0.535845</td><td>-0.273947</td><td>-0.124959</td><td>0.056438</td><td>0.311539</td><td>0.465377</td><td>0.554022</td><td>1.663491</td><td>0.152084</td><td>0.468778</td><td>0.383696</td><td>0.618529</td><td>0.435326</td><td>0.415523</td><td>0.356895</td><td>1.319538</td><td>0.955549</td><td>0.789646</td><td>1.044941</td><td>1.353001</td><td>0.72392</td><td>0.613462</td><td>0.246212</td><td>0.936911</td><td>0.942204</td><td>0.940304</td><td>0.942497</td><td>&hellip;</td><td>0.400075</td><td>-0.322244</td><td>0.183687</td><td>0.404295</td><td>-0.169373</td><td>0.386584</td><td>-0.314775</td><td>-1.024058</td><td>-0.09459</td><td>1.735322</td><td>0.620057</td><td>-0.094702</td><td>0.69121</td><td>0.24193</td><td>2.525526</td><td>4.292975</td><td>0.350791</td><td>0.32357</td><td>0.753829</td><td>0.913363</td><td>1.002985</td><td>1.928621</td><td>1.849608</td><td>0.004398</td><td>0.172967</td><td>0.351832</td><td>0.368358</td><td>0.208416</td><td>0.158524</td><td>0.529534</td><td>2023-03-01 00:03:00</td><td>0.23149</td><td>2.686731</td><td>-16.151</td><td>210.779</td><td>460.705</td><td>25.881</td></tr><tr><td>142.818</td><td>0.17382</td><td>-0.213489</td><td>0.096067</td><td>0.215709</td><td>0.107133</td><td>0.078976</td><td>0.087818</td><td>0.120426</td><td>0.763537</td><td>-0.430945</td><td>-0.205298</td><td>-0.062118</td><td>0.117266</td><td>0.341493</td><td>0.495591</td><td>0.584519</td><td>1.668419</td><td>0.156177</td><td>0.472732</td><td>0.3871</td><td>0.623192</td><td>0.439034</td><td>0.419868</td><td>0.361572</td><td>1.324595</td><td>0.90546</td><td>0.78375</td><td>1.047708</td><td>1.36188</td><td>0.732001</td><td>0.622712</td><td>0.251095</td><td>0.931761</td><td>0.936818</td><td>0.928362</td><td>0.930464</td><td>&hellip;</td><td>0.391759</td><td>-0.369625</td><td>0.192377</td><td>0.415438</td><td>-0.198976</td><td>0.389969</td><td>-0.312628</td><td>-1.02406</td><td>0.162221</td><td>1.712096</td><td>0.618703</td><td>-0.091884</td><td>0.691207</td><td>0.241928</td><td>2.52443</td><td>4.306694</td><td>0.335599</td><td>0.31907</td><td>0.747533</td><td>0.908904</td><td>1.001286</td><td>1.927084</td><td>1.84895</td><td>0.004008</td><td>0.167391</td><td>0.346066</td><td>0.365314</td><td>0.207839</td><td>0.158304</td><td>0.529167</td><td>2023-03-01 00:04:00</td><td>7.869603</td><td>2.216115</td><td>23.707</td><td>54.004</td><td>142.818</td><td>30.609</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>94.388</td><td>0.020155</td><td>0.076565</td><td>0.228994</td><td>0.288856</td><td>0.151634</td><td>0.108347</td><td>0.088073</td><td>0.073729</td><td>0.071211</td><td>0.460379</td><td>0.494391</td><td>0.372694</td><td>0.270015</td><td>0.089571</td><td>0.096287</td><td>0.109409</td><td>0.78486</td><td>2.031313</td><td>1.673446</td><td>0.641512</td><td>0.772499</td><td>0.773449</td><td>0.956571</td><td>0.899399</td><td>0.477649</td><td>0.120275</td><td>0.017187</td><td>0.166928</td><td>0.519881</td><td>0.607589</td><td>0.797609</td><td>0.31223</td><td>0.459993</td><td>0.47937</td><td>0.48488</td><td>0.454508</td><td>&hellip;</td><td>0.807352</td><td>0.035728</td><td>0.551648</td><td>1.233784</td><td>-0.252775</td><td>-0.040562</td><td>-0.347201</td><td>-0.21873</td><td>0.636555</td><td>0.533902</td><td>0.142461</td><td>-0.768709</td><td>0.260958</td><td>0.197249</td><td>1.776607</td><td>2.702758</td><td>0.204378</td><td>0.270656</td><td>0.750338</td><td>1.060258</td><td>1.450851</td><td>3.219345</td><td>3.340686</td><td>0.008679</td><td>0.224656</td><td>0.401595</td><td>0.393726</td><td>0.212651</td><td>0.136494</td><td>0.243172</td><td>2024-02-29 23:55:00</td><td>0.611756</td><td>0.705263</td><td>-2.642</td><td>-16.314</td><td>94.388</td><td>10.968</td></tr><tr><td>177.372</td><td>0.016262</td><td>0.062527</td><td>0.214072</td><td>0.276463</td><td>0.146521</td><td>0.104164</td><td>0.084063</td><td>0.069788</td><td>0.024066</td><td>0.332808</td><td>0.387194</td><td>0.27384</td><td>0.174273</td><td>0.042308</td><td>0.049073</td><td>0.06222</td><td>0.811096</td><td>1.942052</td><td>1.721022</td><td>0.682607</td><td>0.818153</td><td>0.79747</td><td>0.981444</td><td>0.924992</td><td>0.496542</td><td>0.246743</td><td>0.089766</td><td>0.238524</td><td>0.590531</td><td>0.643586</td><td>0.834236</td><td>0.330893</td><td>0.446043</td><td>0.478758</td><td>0.474246</td><td>0.461256</td><td>&hellip;</td><td>0.813372</td><td>0.052891</td><td>0.572652</td><td>1.236672</td><td>-0.253142</td><td>-0.027268</td><td>-0.220352</td><td>-0.206114</td><td>0.649406</td><td>0.544298</td><td>0.149768</td><td>-0.779659</td><td>0.260872</td><td>0.197186</td><td>1.807592</td><td>2.742924</td><td>0.213951</td><td>0.271922</td><td>0.748216</td><td>1.056653</td><td>1.448602</td><td>3.216719</td><td>3.339353</td><td>0.007928</td><td>0.217422</td><td>0.395019</td><td>0.390476</td><td>0.212063</td><td>0.136305</td><td>0.243004</td><td>2024-02-29 23:56:00</td><td>0.564317</td><td>1.640604</td><td>-1.768</td><td>43.03</td><td>177.372</td><td>6.348</td></tr><tr><td>101.252</td><td>0.045407</td><td>0.109834</td><td>0.263577</td><td>0.329266</td><td>0.174214</td><td>0.13294</td><td>0.113052</td><td>0.098865</td><td>-0.05737</td><td>0.154488</td><td>0.217087</td><td>0.10915</td><td>0.011308</td><td>-0.039019</td><td>-0.032317</td><td>-0.019202</td><td>0.498355</td><td>0.628261</td><td>0.454894</td><td>0.056188</td><td>0.191078</td><td>0.483386</td><td>0.667775</td><td>0.611826</td><td>0.458054</td><td>-0.055595</td><td>-0.062112</td><td>0.083189</td><td>0.432974</td><td>0.565042</td><td>0.756211</td><td>0.292203</td><td>0.365089</td><td>0.420895</td><td>0.399799</td><td>0.422313</td><td>&hellip;</td><td>0.803276</td><td>0.024071</td><td>0.54706</td><td>1.191918</td><td>-0.342808</td><td>-0.065439</td><td>-0.220704</td><td>-0.206118</td><td>0.535593</td><td>0.498593</td><td>0.150411</td><td>-0.805622</td><td>0.260703</td><td>0.197062</td><td>1.7447</td><td>2.73189</td><td>0.210581</td><td>0.268868</td><td>0.741793</td><td>1.050909</td><td>1.445661</td><td>3.213444</td><td>3.33774</td><td>0.007243</td><td>0.210421</td><td>0.388549</td><td>0.387252</td><td>0.211477</td><td>0.136117</td><td>0.242836</td><td>2024-02-29 23:57:00</td><td>1.438736</td><td>2.292427</td><td>1.597</td><td>39.746</td><td>101.252</td><td>8.877</td></tr><tr><td>74.56</td><td>0.124783</td><td>0.244168</td><td>0.408704</td><td>0.480016</td><td>0.251493</td><td>0.211727</td><td>0.19216</td><td>0.178116</td><td>0.111335</td><td>0.44718</td><td>0.53661</td><td>0.439239</td><td>0.345835</td><td>0.129327</td><td>0.136199</td><td>0.149399</td><td>0.803323</td><td>1.680122</td><td>1.620743</td><td>0.655204</td><td>0.794395</td><td>0.78617</td><td>0.971394</td><td>0.916158</td><td>0.496689</td><td>0.230439</td><td>0.089445</td><td>0.23383</td><td>0.582657</td><td>0.640532</td><td>0.832325</td><td>0.330608</td><td>0.441305</td><td>0.467176</td><td>0.460681</td><td>0.446152</td><td>&hellip;</td><td>0.807143</td><td>0.035102</td><td>0.568606</td><td>1.212147</td><td>-0.369407</td><td>-0.035077</td><td>-0.221043</td><td>-0.206122</td><td>0.647059</td><td>0.528757</td><td>0.151051</td><td>-0.774165</td><td>0.260957</td><td>0.197257</td><td>1.74259</td><td>2.643514</td><td>0.203284</td><td>0.264413</td><td>0.733953</td><td>1.044452</td><td>1.442484</td><td>3.209945</td><td>3.33603</td><td>0.006608</td><td>0.203642</td><td>0.382184</td><td>0.384054</td><td>0.210892</td><td>0.135928</td><td>0.242668</td><td>2024-02-29 23:58:00</td><td>1.169353</td><td>0.428489</td><td>0.83</td><td>-29.83</td><td>74.56</td><td>10.632</td></tr><tr><td>303.722</td><td>0.368659</td><td>0.665382</td><td>0.867538</td><td>0.951903</td><td>0.491276</td><td>0.454342</td><td>0.435431</td><td>0.4217</td><td>0.330298</td><td>0.804642</td><td>0.9431</td><td>0.862786</td><td>0.777285</td><td>0.347325</td><td>0.354669</td><td>0.368107</td><td>1.128738</td><td>2.710711</td><td>2.828132</td><td>1.284624</td><td>1.433281</td><td>1.108506</td><td>1.295011</td><td>1.240712</td><td>0.602761</td><td>0.980926</td><td>0.497163</td><td>0.647331</td><td>0.998625</td><td>0.850315</td><td>1.043021</td><td>0.436378</td><td>0.58741</td><td>0.606344</td><td>0.59148</td><td>0.555941</td><td>&hellip;</td><td>0.776366</td><td>-0.052765</td><td>0.597701</td><td>1.450874</td><td>-0.436284</td><td>0.202887</td><td>-0.221368</td><td>-0.206125</td><td>0.331538</td><td>0.669032</td><td>0.151687</td><td>-0.66805</td><td>0.261324</td><td>0.197537</td><td>1.790457</td><td>2.627113</td><td>0.232998</td><td>0.272984</td><td>0.739299</td><td>1.044576</td><td>1.441416</td><td>3.208415</td><td>3.335166</td><td>0.006072</td><td>0.197096</td><td>0.375931</td><td>0.380886</td><td>0.21031</td><td>0.135741</td><td>0.242501</td><td>2024-02-29 23:59:00</td><td>1.015524</td><td>0.398757</td><td>0.06</td><td>-130.552</td><td>303.722</td><td>7.79</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (525_887, 871)\n",
       "┌─────────┬──────────┬───────────┬───────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
       "│ volume  ┆ X1       ┆ X2        ┆ X3        ┆ … ┆ bidask_del ┆ buysell_de ┆ buysell_s ┆ bidask_si │\n",
       "│ ---     ┆ ---      ┆ ---       ┆ ---       ┆   ┆ ta         ┆ lta        ┆ ize       ┆ ze        │\n",
       "│ f64     ┆ f64      ┆ f64       ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
       "│         ┆          ┆           ┆           ┆   ┆ f64        ┆ f64        ┆ f64       ┆ f64       │\n",
       "╞═════════╪══════════╪═══════════╪═══════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 221.389 ┆ 0.121263 ┆ -0.41769  ┆ 0.005399  ┆ … ┆ 6.858      ┆ 131.421    ┆ 221.389   ┆ 23.708    │\n",
       "│ 847.796 ┆ 0.302841 ┆ -0.049576 ┆ 0.356667  ┆ … ┆ 36.254     ┆ 203.896    ┆ 847.796   ┆ 40.926    │\n",
       "│ 295.596 ┆ 0.167462 ┆ -0.291212 ┆ 0.083138  ┆ … ┆ -59.808    ┆ 22.858     ┆ 295.596   ┆ 60.692    │\n",
       "│ 460.705 ┆ 0.072944 ┆ -0.43659  ┆ -0.102483 ┆ … ┆ -16.151    ┆ 210.779    ┆ 460.705   ┆ 25.881    │\n",
       "│ 142.818 ┆ 0.17382  ┆ -0.213489 ┆ 0.096067  ┆ … ┆ 23.707     ┆ 54.004     ┆ 142.818   ┆ 30.609    │\n",
       "│ …       ┆ …        ┆ …         ┆ …         ┆ … ┆ …          ┆ …          ┆ …         ┆ …         │\n",
       "│ 94.388  ┆ 0.020155 ┆ 0.076565  ┆ 0.228994  ┆ … ┆ -2.642     ┆ -16.314    ┆ 94.388    ┆ 10.968    │\n",
       "│ 177.372 ┆ 0.016262 ┆ 0.062527  ┆ 0.214072  ┆ … ┆ -1.768     ┆ 43.03      ┆ 177.372   ┆ 6.348     │\n",
       "│ 101.252 ┆ 0.045407 ┆ 0.109834  ┆ 0.263577  ┆ … ┆ 1.597      ┆ 39.746     ┆ 101.252   ┆ 8.877     │\n",
       "│ 74.56   ┆ 0.124783 ┆ 0.244168  ┆ 0.408704  ┆ … ┆ 0.83       ┆ -29.83     ┆ 74.56     ┆ 10.632    │\n",
       "│ 303.722 ┆ 0.368659 ┆ 0.665382  ┆ 0.867538  ┆ … ┆ 0.06       ┆ -130.552   ┆ 303.722   ┆ 7.79      │\n",
       "└─────────┴──────────┴───────────┴───────────┴───┴────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"label\"]\n",
    "X, drop_columns = preprocess_train(\n",
    "    data,\n",
    "    columns_to_drop=[\"label\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    ")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96599172",
   "metadata": {
    "papermill": {
     "duration": 0.003954,
     "end_time": "2025-06-10T09:24:38.236899",
     "exception": false,
     "start_time": "2025-06-10T09:24:38.232945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1.2 Time Series Split Functions\n",
    "\n",
    "1. `split_rollingwindow` - rolling window.\n",
    "3. `split_overlapwindow` - overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b8cd57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:38.245843Z",
     "iopub.status.busy": "2025-06-10T09:24:38.245570Z",
     "iopub.status.idle": "2025-06-10T09:24:38.250781Z",
     "shell.execute_reply": "2025-06-10T09:24:38.250068Z"
    },
    "papermill": {
     "duration": 0.011115,
     "end_time": "2025-06-10T09:24:38.251972",
     "exception": false,
     "start_time": "2025-06-10T09:24:38.240857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_rollingwindow(X, n_splits=5, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Rolling window time series splitter with fixed train/test ratio and number of splits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like or DataFrame\n",
    "        Dataset with time-ordering preserved.\n",
    "    n_splits : int\n",
    "        Number of rolling splits.\n",
    "    train_ratio : float\n",
    "        Proportion of each window used for training (e.g. 0.8 for 80/20 split).\n",
    "    \n",
    "    Yields\n",
    "    ------\n",
    "    train_idx, test_idx : range, range\n",
    "        Index ranges for training and testing.\n",
    "    \"\"\"\n",
    "    n_obs = len(X)\n",
    "    window_size = n_obs // (n_splits + 1)\n",
    "    train_size = int(train_ratio * window_size)\n",
    "    test_size = window_size - train_size\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        start = i * window_size\n",
    "        train_start = start\n",
    "        train_end = train_start + train_size\n",
    "        test_start = train_end\n",
    "        test_end = test_start + test_size\n",
    "\n",
    "        if test_end > n_obs:\n",
    "            break\n",
    "\n",
    "        yield range(train_start, train_end), range(test_start, test_end)\n",
    "\n",
    "# splits = rolling_window_split(X=X, n_splits = 5, train_ratio=0.5)\n",
    "# for train_idx, test_idx in splits:\n",
    "#     print(train_idx, test_idx)\n",
    "# #     df_train = X.slice(train_idx.start, len(train_idx))\n",
    "# #     df_test = X.slice(test_idx.start, len(test_idx))\n",
    "\n",
    "# for i, (train_idx, test_idx) in enumerate(splits):\n",
    "#     if i == 1:  # second batch (index 1)\n",
    "#         df_train = X.slice(train_idx.start, len(train_idx))\n",
    "#         df_test = X.slice(test_idx.start, len(test_idx))\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e7b285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:38.261010Z",
     "iopub.status.busy": "2025-06-10T09:24:38.260757Z",
     "iopub.status.idle": "2025-06-10T09:24:38.266917Z",
     "shell.execute_reply": "2025-06-10T09:24:38.266165Z"
    },
    "papermill": {
     "duration": 0.011986,
     "end_time": "2025-06-10T09:24:38.268041",
     "exception": false,
     "start_time": "2025-06-10T09:24:38.256055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 100000) range(100000, 200000)\n",
      "range(10000, 110000) range(110000, 210000)\n",
      "range(20000, 120000) range(120000, 220000)\n",
      "range(30000, 130000) range(130000, 230000)\n",
      "range(40000, 140000) range(140000, 240000)\n",
      "range(50000, 150000) range(150000, 250000)\n",
      "range(60000, 160000) range(160000, 260000)\n",
      "range(70000, 170000) range(170000, 270000)\n",
      "range(80000, 180000) range(180000, 280000)\n",
      "range(90000, 190000) range(190000, 290000)\n",
      "range(100000, 200000) range(200000, 300000)\n",
      "range(110000, 210000) range(210000, 310000)\n",
      "range(120000, 220000) range(220000, 320000)\n",
      "range(130000, 230000) range(230000, 330000)\n",
      "range(140000, 240000) range(240000, 340000)\n",
      "range(150000, 250000) range(250000, 350000)\n",
      "range(160000, 260000) range(260000, 360000)\n",
      "range(170000, 270000) range(270000, 370000)\n",
      "range(180000, 280000) range(280000, 380000)\n",
      "range(190000, 290000) range(290000, 390000)\n",
      "range(200000, 300000) range(300000, 400000)\n",
      "range(210000, 310000) range(310000, 410000)\n",
      "range(220000, 320000) range(320000, 420000)\n",
      "range(230000, 330000) range(330000, 430000)\n",
      "range(240000, 340000) range(340000, 440000)\n",
      "range(250000, 350000) range(350000, 450000)\n",
      "range(260000, 360000) range(360000, 460000)\n",
      "range(270000, 370000) range(370000, 470000)\n",
      "range(280000, 380000) range(380000, 480000)\n",
      "range(290000, 390000) range(390000, 490000)\n",
      "range(300000, 400000) range(400000, 500000)\n",
      "range(310000, 410000) range(410000, 510000)\n",
      "range(320000, 420000) range(420000, 520000)\n"
     ]
    }
   ],
   "source": [
    "def split_overlapwindow(X, train_size, test_size, step):\n",
    "    \"\"\"\n",
    "    Rolling window splitter with overlapping train/test splits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like or DataFrame\n",
    "        Dataset with time-ordering preserved.\n",
    "    train_size : int\n",
    "        Number of observations in each training window.\n",
    "    test_size : int\n",
    "        Number of observations in each test window.\n",
    "    step : int\n",
    "        Forward step size between each split.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    train_idx, test_idx : range, range\n",
    "        Index ranges for training and testing.\n",
    "    \"\"\"\n",
    "    n_obs = len(X)\n",
    "    start = 0\n",
    "    while (start + train_size + test_size) <= n_obs:\n",
    "        train_start = start\n",
    "        train_end = train_start + train_size\n",
    "        test_start = train_end\n",
    "        test_end = test_start + test_size\n",
    "\n",
    "        yield range(train_start, train_end), range(test_start, test_end)\n",
    "        start += step\n",
    "\n",
    "train_size = 100000\n",
    "test_size = 100000\n",
    "step = 10000\n",
    "splits = split_overlapwindow(X, train_size, test_size, step)\n",
    "for train_idx, test_idx in splits:\n",
    "    print(train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c34ba",
   "metadata": {
    "papermill": {
     "duration": 0.00383,
     "end_time": "2025-06-10T09:24:38.275972",
     "exception": false,
     "start_time": "2025-06-10T09:24:38.272142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2 Iterative Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b0801",
   "metadata": {
    "papermill": {
     "duration": 0.003662,
     "end_time": "2025-06-10T09:24:38.283460",
     "exception": false,
     "start_time": "2025-06-10T09:24:38.279798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c57493d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:38.292619Z",
     "iopub.status.busy": "2025-06-10T09:24:38.292302Z",
     "iopub.status.idle": "2025-06-10T09:24:40.147061Z",
     "shell.execute_reply": "2025-06-10T09:24:40.146517Z"
    },
    "papermill": {
     "duration": 1.860852,
     "end_time": "2025-06-10T09:24:40.148447",
     "exception": false,
     "start_time": "2025-06-10T09:24:38.287595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# model = XGBRegressor(\n",
    "#     tree_method=\"gpu_hist\",\n",
    "#     predictor=\"gpu_predictor\",\n",
    "#     n_estimators=100,\n",
    "#     max_depth=8,\n",
    "#     learning_rate=0.05,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "model = XGBRegressor(\n",
    "    tree_method = \"hist\", \n",
    "    device = \"cuda\",\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# Convert your data to GPU arrays\n",
    "# X_gpu = cp.asarray(X.to_numpy())\n",
    "# y_gpu = cp.asarray(y.to_numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fcc8cd",
   "metadata": {
    "papermill": {
     "duration": 0.003776,
     "end_time": "2025-06-10T09:24:40.156460",
     "exception": false,
     "start_time": "2025-06-10T09:24:40.152684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9f7f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:40.165901Z",
     "iopub.status.busy": "2025-06-10T09:24:40.165560Z",
     "iopub.status.idle": "2025-06-10T09:24:42.165210Z",
     "shell.execute_reply": "2025-06-10T09:24:42.164443Z"
    },
    "papermill": {
     "duration": 2.006336,
     "end_time": "2025-06-10T09:24:42.166693",
     "exception": false,
     "start_time": "2025-06-10T09:24:40.160357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import uuid\n",
    "import cupy as cp  # You'll need cupy installed\n",
    "\n",
    "# def iterative_featureselection_onesplit(model, X, y, split_fn, scoring, drop_fraction = 0.1, min_features = 10):\n",
    "#     results = []\n",
    "#     splits = list(split_fn(X))\n",
    "#     n_splits = len(splits)\n",
    "\n",
    "#     current_X = X.copy()\n",
    "#     iteration = 0\n",
    "    \n",
    "#     while current_X.shape[1] > min_features:\n",
    "#         iteration += 1\n",
    "#         print(f\"\\n[+] Iteration {iteration} - {current_X.shape[1]} features\")\n",
    "        \n",
    "#         training_model = clone(model)\n",
    "#         training_model.fit(current_X, y)\n",
    "#         importances = pd.Series(fitted_model.feature_importances_, index=current_X.columns)\n",
    "\n",
    "#         scores = []\n",
    "#         for i, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "#             print(f\"    [Fold {i}/{n_splits}] ...\", end=\"\\r\")\n",
    "            \n",
    "            \n",
    "#             X_train, y_train = current_X.iloc[train_idx], y.iloc[train_idx]\n",
    "#             X_test, y_test = current_X.iloc[test_idx], y.iloc[test_idx]\n",
    "        \n",
    "#             fold_model = clone(model)\n",
    "#             fold_model.fit(X_train, y_train)\n",
    "        \n",
    "#             preds = fold_model.predict(X_test)\n",
    "#             score = scoring(y_test, preds)\n",
    "#             scores.append(score)\n",
    "        \n",
    "#         mean_score = np.mean(score)\n",
    "\n",
    "#         results.append({\n",
    "#             \"iteration\" : iteration,\n",
    "#             \"model_name\": model.__class__.__name__\n",
    "#             \"num_features\": current_X.shape[1],\n",
    "#             \"features\": current_X.columns.tolist(),\n",
    "#             \"score_mean\": mean_score,\n",
    "#         })\n",
    "#         n_drop = max(10, int(len(importances) * drop_fraction))\n",
    "#         drop_cols = importances.nsmallest(n_drop).index\n",
    "#         current_X = current_X.drop(columns=drop_cols)\n",
    "\n",
    "#     print(f\"\\n[*] Finished: {current_X.shape[1]} features remaining (≤ min_features={min_features})\")\n",
    "#     return results\n",
    "\n",
    "# results = iterative_featureselection(\n",
    "#     model=model,\n",
    "#     X=X,\n",
    "#     y=y,\n",
    "#     split_fn=lambda X: rolling_window_split(X, train_size=100_000, test_size=20_000, step=20_000),\n",
    "#     drop_fraction=0.1,\n",
    "#     min_features=50,\n",
    "#     scoring=pearson_corr\n",
    "# )\n",
    "\n",
    "def iterative_featureselection(\n",
    "    model,\n",
    "    X: pl.DataFrame,\n",
    "    y: pl.Series,\n",
    "    split_fn,\n",
    "    scorers: dict,\n",
    "    drop_fraction: float = 0.1,\n",
    "    min_features: int = 10,\n",
    "    use_shap: bool = False,\n",
    "    use_gpu : bool = True\n",
    ") -> list:\n",
    "    ID = uuid.uuid4().hex\n",
    "    results = []\n",
    "    splits = list(split_fn(X))\n",
    "    n_splits = len(splits)\n",
    "\n",
    "    current_X = X.clone()\n",
    "    feature_cols = current_X.columns\n",
    "    iteration = 0\n",
    "\n",
    "    # Convert y to appropriate format\n",
    "    if use_gpu:\n",
    "        try:\n",
    "            import cupy as cp\n",
    "            y_np = cp.asarray(y.to_numpy().flatten())\n",
    "        except ImportError:\n",
    "            print(\"CuPy not available, falling back to CPU\")\n",
    "            y_np = y.to_numpy().flatten()\n",
    "            use_gpu = False\n",
    "\n",
    "    while len(feature_cols) > min_features:\n",
    "        iteration += 1\n",
    "        print(f\"\\n[+] Iteration {iteration} - {len(feature_cols)} features\")\n",
    "\n",
    "        # Extract feature matrix\n",
    "        X_np = current_X.select(feature_cols).to_numpy()\n",
    "        if use_gpu:\n",
    "            X_np = cp.asarray(X_np)\n",
    "            \n",
    "        # Fit full model for feature importances\n",
    "        training_model = clone(model)\n",
    "        training_model.fit(X_np, y_np)\n",
    "\n",
    "        # 1. Compute raw importances as a NumPy array\n",
    "        if use_shap:\n",
    "            explainer   = shap.TreeExplainer(training_model)\n",
    "            shap_vals   = explainer.shap_values(X_np)          # shape (n_samples, n_features)\n",
    "            imp_array   = np.abs(shap_vals).mean(axis=0)        # mean(|SHAP|) per feature\n",
    "        else:\n",
    "            imp_array   = np.array(training_model.feature_importances_)\n",
    "        \n",
    "        # 2. Build a Polars DataFrame of (feature, importance)\n",
    "        importances_df = pl.DataFrame({\n",
    "            \"feature\": feature_cols,\n",
    "            \"importance\": imp_array.tolist()\n",
    "        })\n",
    "        \n",
    "        # Cross-validation\n",
    "        metrics = {k: [] for k in scorers}\n",
    "\n",
    "        for i, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "            print(f\"    [Fold {i}/{n_splits}] ...\", end=\"\\r\")\n",
    "\n",
    "            X_train, y_train = X_np[train_idx], y_np[train_idx]\n",
    "            X_test, y_test = X_np[test_idx], y_np[test_idx]\n",
    "\n",
    "            fold_model = clone(model)\n",
    "            fold_model.fit(X_train, y_train)\n",
    "            y_pred = fold_model.predict(X_test)\n",
    "\n",
    "            for name, func in scorers.items():\n",
    "                y_test = y_test.get() if hasattr(y_test, 'get') else y_test\n",
    "                y_pred = y_pred.get() if hasattr(y_pred, 'get') else y_pred\n",
    "                metrics[name].append(func(y_test, y_pred))\n",
    "\n",
    "        # Mean metric values\n",
    "        mean_metrics = {name: np.mean(vals) for name, vals in metrics.items()}\n",
    "\n",
    "        results.append({\n",
    "            \"ID\": ID,\n",
    "            \"params\": {\n",
    "                \"drop_fraction\" : drop_fraction,\n",
    "                \"min_features\": min_features,\n",
    "                \"use_shap\" : use_shap,\n",
    "                \"use_gpu\" : use_gpu\n",
    "            },\n",
    "            \"num_features\": len(feature_cols),\n",
    "            \"features\": feature_cols.copy(),\n",
    "            **{f\"scores_{name}_mean\": val for name, val in mean_metrics.items()}\n",
    "        })\n",
    "\n",
    "        print(\"    → \" + \" | \".join([f\"{k.upper()}: {v:.4f}\" for k, v in mean_metrics.items()]))\n",
    "\n",
    "        # 3. Identify the n_drop least important features\n",
    "        n_drop    = max(10, int(len(feature_cols) * drop_fraction))\n",
    "        drop_cols = (\n",
    "            importances_df\n",
    "            .sort(\"importance\")        # ascending\n",
    "            .head(n_drop)              # take the smallest n_drop\n",
    "            .get_column(\"feature\")     # extract the feature column\n",
    "            .to_list()                 # into a Python list for filtering\n",
    "        )\n",
    "        \n",
    "        # 4. Filter out dropped features in your Polars DataFrame\n",
    "        feature_cols = [f for f in feature_cols if f not in drop_cols]\n",
    "        current_X    = current_X.select(feature_cols)\n",
    "\n",
    "    print(f\"\"\"\\n {\"[\"+ \"*\" * 10 + \"]\"} Finished: {len(feature_cols)} features remaining (≤ min_features={min_features}) {\"[\"+ \"*\" * 10 + \"]\"}\"\"\")\n",
    "    return results\n",
    "    \n",
    "def pearson_corr(y_true, y_pred):\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "scorers = {\n",
    "    \"pearson\": pearson_corr,\n",
    "    \"mse\": mean_squared_error,\n",
    "    \"mae\": mean_absolute_error\n",
    "}\n",
    "\n",
    "# Test\n",
    "# results = iterative_featureselection(\n",
    "#     model=model,\n",
    "#     X=X,\n",
    "#     y=y,\n",
    "#     split_fn=lambda X:split_rollingwindow(X=X, n_splits = 2, train_ratio=0.5),\n",
    "#     scorers = scorers,\n",
    "#     drop_fraction=0.9,\n",
    "#     min_features=100,\n",
    "#     use_shap = False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ca2b25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:42.176704Z",
     "iopub.status.busy": "2025-06-10T09:24:42.176315Z",
     "iopub.status.idle": "2025-06-10T09:24:42.181416Z",
     "shell.execute_reply": "2025-06-10T09:24:42.180897Z"
    },
    "papermill": {
     "duration": 0.011619,
     "end_time": "2025-06-10T09:24:42.182560",
     "exception": false,
     "start_time": "2025-06-10T09:24:42.170941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_results_to_json(results, out_path):\n",
    "    \"\"\"Save results to JSON file, appending if file exists\"\"\"\n",
    "    \n",
    "    if os.path.exists(out_path):\n",
    "        try:\n",
    "            # Load existing data\n",
    "            with open(out_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "            \n",
    "            # Ensure existing_data is a list\n",
    "            if not isinstance(existing_data, list):\n",
    "                existing_data = [existing_data]\n",
    "            \n",
    "            # Append new results\n",
    "            existing_data.extend(results)\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            # If existing file is corrupted, start fresh\n",
    "            print(\"Warning: Existing JSON file corrupted, starting fresh\")\n",
    "            existing_data = results\n",
    "        \n",
    "        # Save combined data\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(existing_data, f, indent=2)\n",
    "    else:\n",
    "        # Create new file\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "            \n",
    "# out_path = \"/kaggle/working/iterative_featuresselection.json\"\n",
    "# save_results_to_json(results, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018bf116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:42.190999Z",
     "iopub.status.busy": "2025-06-10T09:24:42.190794Z",
     "iopub.status.idle": "2025-06-10T09:24:42.194082Z",
     "shell.execute_reply": "2025-06-10T09:24:42.193433Z"
    },
    "papermill": {
     "duration": 0.008662,
     "end_time": "2025-06-10T09:24:42.195100",
     "exception": false,
     "start_time": "2025-06-10T09:24:42.186438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Training for Iteration 1 (shap=True)...\")\n",
    "# iter_1 = iterative_featureselection(\n",
    "#     model=model,\n",
    "#     X=X,\n",
    "#     y=y,\n",
    "#     split_fn=lambda X:split_rollingwindow(X=X, n_splits = 10, train_ratio=0.5),\n",
    "#     # split_fn=lambda X:split_overlapwindow(X, 50000, 50000, 25000),\n",
    "#     scorers = scorers,\n",
    "#     drop_fraction=0.1,\n",
    "#     min_features=10,\n",
    "#     use_shap = True\n",
    "# )\n",
    "# out_path = \"/kaggle/working/iterative_featuresselection.json\"\n",
    "# save_results_to_json(iter_1, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4aae69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:24:42.203659Z",
     "iopub.status.busy": "2025-06-10T09:24:42.203443Z",
     "iopub.status.idle": "2025-06-10T09:39:25.386211Z",
     "shell.execute_reply": "2025-06-10T09:39:25.385535Z"
    },
    "papermill": {
     "duration": 883.189862,
     "end_time": "2025-06-10T09:39:25.388831",
     "exception": false,
     "start_time": "2025-06-10T09:24:42.198969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Iteration 2 (shap = False)...\n",
      "\n",
      "[+] Iteration 1 - 871 features\n",
      "    → PEARSON: 0.0655 | MSE: 1.7711 | MAE: 0.8491\n",
      "\n",
      "[+] Iteration 2 - 784 features\n",
      "    → PEARSON: 0.0647 | MSE: 1.8442 | MAE: 0.8674\n",
      "\n",
      "[+] Iteration 3 - 706 features\n",
      "    → PEARSON: 0.0705 | MSE: 1.9058 | MAE: 0.8805\n",
      "\n",
      "[+] Iteration 4 - 636 features\n",
      "    → PEARSON: 0.0641 | MSE: 1.8127 | MAE: 0.8572\n",
      "\n",
      "[+] Iteration 5 - 573 features\n",
      "    → PEARSON: 0.0606 | MSE: 1.7308 | MAE: 0.8560\n",
      "\n",
      "[+] Iteration 6 - 516 features\n",
      "    → PEARSON: 0.0672 | MSE: 1.8002 | MAE: 0.8849\n",
      "\n",
      "[+] Iteration 7 - 465 features\n",
      "    → PEARSON: 0.0690 | MSE: 1.8200 | MAE: 0.8726\n",
      "\n",
      "[+] Iteration 8 - 419 features\n",
      "    → PEARSON: 0.0615 | MSE: 2.0603 | MAE: 0.9047\n",
      "\n",
      "[+] Iteration 9 - 378 features\n",
      "    → PEARSON: 0.0658 | MSE: 2.0475 | MAE: 0.9332\n",
      "\n",
      "[+] Iteration 10 - 341 features\n",
      "    → PEARSON: 0.0688 | MSE: 2.0705 | MAE: 0.9136\n",
      "\n",
      "[+] Iteration 11 - 307 features\n",
      "    → PEARSON: 0.0691 | MSE: 2.1278 | MAE: 0.9290\n",
      "\n",
      "[+] Iteration 12 - 277 features\n",
      "    → PEARSON: 0.0630 | MSE: 2.0133 | MAE: 0.9169\n",
      "\n",
      "[+] Iteration 13 - 250 features\n",
      "    → PEARSON: 0.0511 | MSE: 2.1835 | MAE: 0.9678\n",
      "\n",
      "[+] Iteration 14 - 225 features\n",
      "    → PEARSON: 0.0735 | MSE: 2.0223 | MAE: 0.9155\n",
      "\n",
      "[+] Iteration 15 - 203 features\n",
      "    → PEARSON: 0.0668 | MSE: 2.1555 | MAE: 0.9357\n",
      "\n",
      "[+] Iteration 16 - 183 features\n",
      "    → PEARSON: 0.0874 | MSE: 2.0584 | MAE: 0.9342\n",
      "\n",
      "[+] Iteration 17 - 165 features\n",
      "    → PEARSON: 0.0750 | MSE: 2.1638 | MAE: 0.9562\n",
      "\n",
      "[+] Iteration 18 - 149 features\n",
      "    → PEARSON: 0.0633 | MSE: 2.0657 | MAE: 0.9044\n",
      "\n",
      "[+] Iteration 19 - 135 features\n",
      "    → PEARSON: 0.0538 | MSE: 2.2430 | MAE: 0.9654\n",
      "\n",
      "[+] Iteration 20 - 122 features\n",
      "    → PEARSON: 0.0436 | MSE: 2.2567 | MAE: 0.9544\n",
      "\n",
      "[+] Iteration 21 - 110 features\n",
      "    → PEARSON: 0.0522 | MSE: 2.0678 | MAE: 0.9500\n",
      "\n",
      "[+] Iteration 22 - 99 features\n",
      "    → PEARSON: 0.0666 | MSE: 2.0842 | MAE: 0.9400\n",
      "\n",
      "[+] Iteration 23 - 89 features\n",
      "    → PEARSON: 0.0606 | MSE: 2.1296 | MAE: 0.9412\n",
      "\n",
      "[+] Iteration 24 - 79 features\n",
      "    → PEARSON: 0.0353 | MSE: 1.9653 | MAE: 0.9107\n",
      "\n",
      "[+] Iteration 25 - 69 features\n",
      "    → PEARSON: 0.0379 | MSE: 2.1683 | MAE: 0.9462\n",
      "\n",
      "[+] Iteration 26 - 59 features\n",
      "    → PEARSON: 0.0184 | MSE: 2.1186 | MAE: 0.9772\n",
      "\n",
      "[+] Iteration 27 - 49 features\n",
      "    → PEARSON: -0.0039 | MSE: 1.9922 | MAE: 0.9226\n",
      "\n",
      "[+] Iteration 28 - 39 features\n",
      "    → PEARSON: -0.0041 | MSE: 2.2001 | MAE: 0.9662\n",
      "\n",
      "[+] Iteration 29 - 29 features\n",
      "    → PEARSON: -0.0242 | MSE: 2.2026 | MAE: 0.9857\n",
      "\n",
      "[+] Iteration 30 - 19 features\n",
      "    → PEARSON: -0.0297 | MSE: 2.5163 | MAE: 1.0325\n",
      "\n",
      " [**********] Finished: 9 features remaining (≤ min_features=10) [**********]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training for Iteration 2 (shap = False)...\")\n",
    "iter_2 = iterative_featureselection(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    # split_fn=lambda X:split_overlapwindow(X, 50000, 50000, 25000),\n",
    "    split_fn=lambda X:split_rollingwindow(X=X, n_splits = 10, train_ratio=0.5),\n",
    "    scorers = scorers,\n",
    "    drop_fraction=0.1,\n",
    "    min_features=10,\n",
    "    use_shap = False\n",
    ")\n",
    "out_path = \"/kaggle/working/iterative_featuresselection.json\"\n",
    "save_results_to_json(iter_2, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c2876",
   "metadata": {
    "papermill": {
     "duration": 0.015667,
     "end_time": "2025-06-10T09:39:25.420954",
     "exception": false,
     "start_time": "2025-06-10T09:39:25.405287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Current Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b660205c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:39:25.453959Z",
     "iopub.status.busy": "2025-06-10T09:39:25.453684Z",
     "iopub.status.idle": "2025-06-10T09:39:25.497109Z",
     "shell.execute_reply": "2025-06-10T09:39:25.496494Z"
    },
    "papermill": {
     "duration": 0.061499,
     "end_time": "2025-06-10T09:39:25.498417",
     "exception": false,
     "start_time": "2025-06-10T09:39:25.436918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (30, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ID</th><th>params</th><th>num_features</th><th>features</th><th>scores_pearson_mean</th><th>scores_mse_mean</th><th>scores_mae_mean</th></tr><tr><td>str</td><td>struct[4]</td><td>i64</td><td>list[str]</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>871</td><td>[&quot;volume&quot;, &quot;X1&quot;, … &quot;bidask_size&quot;]</td><td>0.065463</td><td>1.771077</td><td>0.849132</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>784</td><td>[&quot;volume&quot;, &quot;X1&quot;, … &quot;bidask_size&quot;]</td><td>0.064749</td><td>1.844201</td><td>0.867401</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>706</td><td>[&quot;X8&quot;, &quot;X9&quot;, … &quot;bidask_size&quot;]</td><td>0.070511</td><td>1.905795</td><td>0.880457</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>636</td><td>[&quot;X15&quot;, &quot;X16&quot;, … &quot;bidask_size&quot;]</td><td>0.064143</td><td>1.812719</td><td>0.857174</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>573</td><td>[&quot;X17&quot;, &quot;X18&quot;, … &quot;timestamp&quot;]</td><td>0.060635</td><td>1.73081</td><td>0.856017</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>59</td><td>[&quot;X426&quot;, &quot;X427&quot;, … &quot;timestamp&quot;]</td><td>0.018354</td><td>2.118647</td><td>0.977204</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>49</td><td>[&quot;X528&quot;, &quot;X533&quot;, … &quot;timestamp&quot;]</td><td>-0.003859</td><td>1.992247</td><td>0.922619</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>39</td><td>[&quot;X535&quot;, &quot;X536&quot;, … &quot;timestamp&quot;]</td><td>-0.004086</td><td>2.200124</td><td>0.966154</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>29</td><td>[&quot;X540&quot;, &quot;X542&quot;, … &quot;timestamp&quot;]</td><td>-0.024157</td><td>2.202599</td><td>0.985654</td></tr><tr><td>&quot;4603eaa462664e56b89978d95cd8f6…</td><td>{0.1,10,false,true}</td><td>19</td><td>[&quot;X542&quot;, &quot;X577&quot;, … &quot;timestamp&quot;]</td><td>-0.029708</td><td>2.516322</td><td>1.032483</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (30, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ ID           ┆ params      ┆ num_feature ┆ features    ┆ scores_pear ┆ scores_mse_ ┆ scores_mae_ │\n",
       "│ ---          ┆ ---         ┆ s           ┆ ---         ┆ son_mean    ┆ mean        ┆ mean        │\n",
       "│ str          ┆ struct[4]   ┆ ---         ┆ list[str]   ┆ ---         ┆ ---         ┆ ---         │\n",
       "│              ┆             ┆ i64         ┆             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 871         ┆ [\"volume\",  ┆ 0.065463    ┆ 1.771077    ┆ 0.849132    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X1\", … \"bi ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ dask_siz…   ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 784         ┆ [\"volume\",  ┆ 0.064749    ┆ 1.844201    ┆ 0.867401    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X1\", … \"bi ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ dask_siz…   ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 706         ┆ [\"X8\",      ┆ 0.070511    ┆ 1.905795    ┆ 0.880457    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X9\", … \"bi ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ dask_size\"] ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 636         ┆ [\"X15\",     ┆ 0.064143    ┆ 1.812719    ┆ 0.857174    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X16\", …    ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ \"bidask_siz ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ e\"…         ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 573         ┆ [\"X17\",     ┆ 0.060635    ┆ 1.73081     ┆ 0.856017    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X18\", …    ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ \"timestamp\" ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ ]           ┆             ┆             ┆             │\n",
       "│ …            ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 59          ┆ [\"X426\",    ┆ 0.018354    ┆ 2.118647    ┆ 0.977204    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X427\", …   ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ \"timestamp\" ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ …           ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 49          ┆ [\"X528\",    ┆ -0.003859   ┆ 1.992247    ┆ 0.922619    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X533\", …   ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ \"timestamp\" ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ …           ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 39          ┆ [\"X535\",    ┆ -0.004086   ┆ 2.200124    ┆ 0.966154    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X536\", …   ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ \"timestamp\" ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ …           ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 29          ┆ [\"X540\",    ┆ -0.024157   ┆ 2.202599    ┆ 0.985654    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X542\", …   ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ \"timestamp\" ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ …           ┆             ┆             ┆             │\n",
       "│ 4603eaa46266 ┆ {0.1,10,fal ┆ 19          ┆ [\"X542\",    ┆ -0.029708   ┆ 2.516322    ┆ 1.032483    │\n",
       "│ 4e56b89978d9 ┆ se,true}    ┆             ┆ \"X577\", …   ┆             ┆             ┆             │\n",
       "│ 5cd8f6…      ┆             ┆             ┆ \"timestamp\" ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ …           ┆             ┆             ┆             │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/kaggle/working/iterative_featuresselection.json\", \"r\") as f:\n",
    "    current_results = json.load(f)\n",
    "\n",
    "current_results_df = pl.DataFrame(current_results)\n",
    "current_results_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11418275,
     "sourceId": 96164,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 912.739143,
   "end_time": "2025-06-10T09:39:29.579032",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-10T09:24:16.839889",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
